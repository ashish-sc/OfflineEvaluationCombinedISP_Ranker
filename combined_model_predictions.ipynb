{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80261a05-ca24-4570-8703-a387ca88e4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import dataclasses\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import cast, Dict, Optional, Sequence, Tuple, Union, List, Text\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_recommenders as tfrs\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "import json\n",
    "#from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "logging.getLogger('tensorflow').propagate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5422a6ea-bba0-4f35-af1f-d00408199451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on bqjob_r7137de3c9a09dc00_0000018703535799_1 ... (64s) Current status: DONE   \n"
     ]
    }
   ],
   "source": [
    "!bq extract --noprint_header --field_delimiter='&' \\\n",
    "     maximal-furnace-783:Ashish_ranker.isp_ranker_data_17 \\\n",
    "     gs://tpu-cg-us/isp_ranker_data_17/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cce3810-61d8-4ca3-8988-1d38f557e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.get_strategy()\n",
    "# tpu_name = \"ashish-hfr2\"\n",
    "# tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu_name)\n",
    "# strategy = tf.distribute.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0fb1dbd-1833-410f-a886-18282409e931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391\n"
     ]
    }
   ],
   "source": [
    "cols = \"isp_date,model,userId,postId,unified_signal1,combined_score,video_play,likes,shares,favs,mrp,mrpw,unified_signal,hour,dayofweek,is_weekend,is_morning,is_afternoon,is_evening,is_night,tagId,pvplay_0,pvplay_1,pvplay_2,pvplay_3,pvplay_4,pvplay_5,pvplay_6,pvplay_7,pvplay_8,pvplay_9,pvplay_10,pvplay_11,pvplay_12,pvplay_13,pvplay_14,pvplay_15,pvplay_16,pvplay_17,pvplay_18,pvplay_19,pvplay_20,pvplay_21,pvplay_22,pvplay_23,pvplay_24,pvplay_25,pvplay_26,pvplay_27,pvplay_28,pvplay_29,pvplay_30,pvplay_31,pvplay_mask,pfav_0,pfav_1,pfav_2,pfav_3,pfav_4,pfav_5,pfav_6,pfav_7,pfav_8,pfav_9,pfav_10,pfav_11,pfav_12,pfav_13,pfav_14,pfav_15,pfav_16,pfav_17,pfav_18,pfav_19,pfav_20,pfav_21,pfav_22,pfav_23,pfav_24,pfav_25,pfav_26,pfav_27,pfav_28,pfav_29,pfav_30,pfav_31,pfav_mask,plike_0,plike_1,plike_2,plike_3,plike_4,plike_5,plike_6,plike_7,plike_8,plike_9,plike_10,plike_11,plike_12,plike_13,plike_14,plike_15,plike_16,plike_17,plike_18,plike_19,plike_20,plike_21,plike_22,plike_23,plike_24,plike_25,plike_26,plike_27,plike_28,plike_29,plike_30,plike_31,plike_mask,pshare_0,pshare_1,pshare_2,pshare_3,pshare_4,pshare_5,pshare_6,pshare_7,pshare_8,pshare_9,pshare_10,pshare_11,pshare_12,pshare_13,pshare_14,pshare_15,pshare_16,pshare_17,pshare_18,pshare_19,pshare_20,pshare_21,pshare_22,pshare_23,pshare_24,pshare_25,pshare_26,pshare_27,pshare_28,pshare_29,pshare_30,pshare_31,pshare_mask,postLikeRatio2h,postShareRatio2h,postFavRatio2h,postCommentRatio2h,postSVPRatio2h,postLPORatio2h,postLikeRatio1D,postShareRatio1D,postFavRatio1D,postCommentRatio1D,postSVPRatio1D,postLPORatio1D,pcLikeRatio2h,pcShareRatio2h,pcFavRatio2h,pcCommentRatio2h,pcSVPRatio2h,pcLPORatio2h,pcLikeRatio1D,pcShareRatio1D,pcFavRatio1D,pcCommentRatio1D,pcSVPRatio1D,pcLPORatio1D,userDistrict,uvplay_0,uvplay_1,uvplay_2,uvplay_3,uvplay_4,uvplay_5,uvplay_6,uvplay_7,uvplay_8,uvplay_9,uvplay_10,uvplay_11,uvplay_12,uvplay_13,uvplay_14,uvplay_15,uvplay_16,uvplay_17,uvplay_18,uvplay_19,uvplay_20,uvplay_21,uvplay_22,uvplay_23,uvplay_24,uvplay_25,uvplay_26,uvplay_27,uvplay_28,uvplay_29,uvplay_30,uvplay_31,uvplay_mask,ufav_0,ufav_1,ufav_2,ufav_3,ufav_4,ufav_5,ufav_6,ufav_7,ufav_8,ufav_9,ufav_10,ufav_11,ufav_12,ufav_13,ufav_14,ufav_15,ufav_16,ufav_17,ufav_18,ufav_19,ufav_20,ufav_21,ufav_22,ufav_23,ufav_24,ufav_25,ufav_26,ufav_27,ufav_28,ufav_29,ufav_30,ufav_31,ufav_mask,ulike_0,ulike_1,ulike_2,ulike_3,ulike_4,ulike_5,ulike_6,ulike_7,ulike_8,ulike_9,ulike_10,ulike_11,ulike_12,ulike_13,ulike_14,ulike_15,ulike_16,ulike_17,ulike_18,ulike_19,ulike_20,ulike_21,ulike_22,ulike_23,ulike_24,ulike_25,ulike_26,ulike_27,ulike_28,ulike_29,ulike_30,ulike_31,ulike_mask,ushare_0,ushare_1,ushare_2,ushare_3,ushare_4,ushare_5,ushare_6,ushare_7,ushare_8,ushare_9,ushare_10,ushare_11,ushare_12,ushare_13,ushare_14,ushare_15,ushare_16,ushare_17,ushare_18,ushare_19,ushare_20,ushare_21,ushare_22,ushare_23,ushare_24,ushare_25,ushare_26,ushare_27,ushare_28,ushare_29,ushare_30,ushare_31,ushare_mask,video_affinity,userLikeRatio1,userShareRatio1,userFavRatio1,userCommentsRatio1,userSVPRatio1,userLPORatio1,userLikeRatio7,userShareRatio7,userFavRatio7,userCommentsRatio7,userSVPRatio7,userLPORatio7,upcLikeRatio1D,upcShareRatio1D,upcFavRatio1D,upcCommentRatio1D,upcSVPRatio1D,upcLPORatio1D,upcLikeRatio3D,upcShareRatio3D,upcFavRatio3D,upcCommentRatio3D,upcSVPRatio3D,upcLPORatio3D,upcLikeRatio7D,upcShareRatio7D,upcFavRatio7D,upcCommentRatio7D,upcSVPRatio7D,upcLPORatio7D,engtag_0,engtag_1,engtag_2,engtag_3,engtag_4,engtag_5,engtag_6,engtag_7,engtag_8,engtag_9,engtag_10,engtag_11,engtag_12,engtag_13,engtag_14,engtag_15,engtag_16,engtag_17,engtag_18,engtag_19,engtag_20,engtag_21,engtag_22,engtag_23,engtag_24,engtag_mask_0,engtag_mask_1,engtag_mask_2,engtag_mask_3,engtag_mask_4,engtag_mask_5,engtag_mask_6,engtag_mask_7,engtag_mask_8,engtag_mask_9,engtag_mask_10,engtag_mask_11,engtag_mask_12,engtag_mask_13,engtag_mask_14,engtag_mask_15,engtag_mask_16,engtag_mask_17,engtag_mask_18,engtag_mask_19,engtag_mask_20,engtag_mask_21,engtag_mask_22,engtag_mask_23,engtag_mask_24\"\n",
    "col_names = cols.split(\",\")\n",
    "print(len(col_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dea6abe-3ec3-484b-ac28-f319b8b2f2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 1\n",
    "\n",
    "hour_feat = 1\n",
    "dayofweek = 1\n",
    "num_other_features = 5\n",
    "\n",
    "sparse_features = [\n",
    "    'userDistrict',\n",
    "    'tagId'\n",
    "]\n",
    "\n",
    "max_sequence_length = 25\n",
    "\n",
    "vocab_sizes = {\n",
    "    'userDistrict': 720,\n",
    "    'tagId': 314000#4000\n",
    "}\n",
    "\n",
    "embedding_dims = {\n",
    "    'userDistrict': 32,\n",
    "    'tagId': 32,\n",
    "}\n",
    "\n",
    "meta = [\n",
    "    'isp_date','model','userId','postId','unified_signal1','combined_score','video_play','likes','shares','favs'\n",
    "]\n",
    "\n",
    "other_feats = [\n",
    "#     \"time_hour\",\"time_dayofweek\",\"time_is_weekend\",\"time_is_morning\",\"time_is_afternoon\",\"time_is_evening\",\"time_is_night\"\n",
    "    'hour', 'dayofweek', 'is_weekend', 'is_morning', 'is_afternoon', 'is_evening', 'is_night'\n",
    "]\n",
    "\n",
    "user_sparse_features = [\n",
    "    'userDistrict'\n",
    "]\n",
    "\n",
    "user_dense_features = [\n",
    "    \"uvplay_0\",\"uvplay_1\",\"uvplay_2\",\"uvplay_3\",\"uvplay_4\",\"uvplay_5\",\"uvplay_6\",\"uvplay_7\",\n",
    "    \"uvplay_8\",\"uvplay_9\",\"uvplay_10\",\"uvplay_11\",\"uvplay_12\",\"uvplay_13\",\"uvplay_14\",\"uvplay_15\",\n",
    "    \"uvplay_16\",\"uvplay_17\",\"uvplay_18\",\"uvplay_19\",\"uvplay_20\",\"uvplay_21\",\"uvplay_22\",\"uvplay_23\",\n",
    "    \"uvplay_24\",\"uvplay_25\",\"uvplay_26\",\"uvplay_27\",\"uvplay_28\",\"uvplay_29\",\"uvplay_30\",\"uvplay_31\",\"uvplay_mask\",\n",
    "    \"ufav_0\",\"ufav_1\",\"ufav_2\",\"ufav_3\",\"ufav_4\",\"ufav_5\",\"ufav_6\",\"ufav_7\",\n",
    "    \"ufav_8\",\"ufav_9\",\"ufav_10\",\"ufav_11\",\"ufav_12\",\"ufav_13\",\"ufav_14\",\"ufav_15\",\n",
    "    \"ufav_16\",\"ufav_17\",\"ufav_18\",\"ufav_19\",\"ufav_20\",\"ufav_21\",\"ufav_22\",\"ufav_23\",\n",
    "    \"ufav_24\",\"ufav_25\",\"ufav_26\",\"ufav_27\",\"ufav_28\",\"ufav_29\",\"ufav_30\",\"ufav_31\",\"ufav_mask\",\n",
    "    \"ulike_0\",\"ulike_1\",\"ulike_2\",\"ulike_3\",\"ulike_4\",\"ulike_5\",\"ulike_6\",\"ulike_7\",\n",
    "    \"ulike_8\",\"ulike_9\",\"ulike_10\",\"ulike_11\",\"ulike_12\",\"ulike_13\",\"ulike_14\",\"ulike_15\",\n",
    "    \"ulike_16\",\"ulike_17\",\"ulike_18\",\"ulike_19\",\"ulike_20\",\"ulike_21\",\"ulike_22\",\"ulike_23\",\n",
    "    \"ulike_24\",\"ulike_25\",\"ulike_26\",\"ulike_27\",\"ulike_28\",\"ulike_29\",\"ulike_30\",\"ulike_31\",\"ulike_mask\",\n",
    "    \"ushare_0\",\"ushare_1\",\"ushare_2\",\"ushare_3\",\"ushare_4\",\"ushare_5\",\"ushare_6\",\"ushare_7\",\n",
    "    \"ushare_8\",\"ushare_9\",\"ushare_10\",\"ushare_11\",\"ushare_12\",\"ushare_13\",\"ushare_14\",\"ushare_15\",\n",
    "    \"ushare_16\",\"ushare_17\",\"ushare_18\",\"ushare_19\",\"ushare_20\",\"ushare_21\",\"ushare_22\",\"ushare_23\",\n",
    "    \"ushare_24\",\"ushare_25\",\"ushare_26\",\"ushare_27\",\"ushare_28\",\"ushare_29\",\"ushare_30\",\"ushare_31\",\"ushare_mask\",\n",
    "    \"video_affinity\",\n",
    "    \"userLikeRatio1\",\"userShareRatio1\",\"userFavRatio1\",\"userCommentsRatio1\",\"userSVPRatio1\",\"userLPORatio1\",\n",
    "    \"userLikeRatio7\",\"userShareRatio7\",\"userFavRatio7\",\"userCommentsRatio7\",\"userSVPRatio7\",\"userLPORatio7\",\n",
    "    \"upcLikeRatio1D\",\"upcShareRatio1D\",\"upcFavRatio1D\",\"upcCommentRatio1D\",\"upcSVPRatio1D\",\"upcLPORatio1D\",\n",
    "    \"upcLikeRatio3D\",\"upcShareRatio3D\",\"upcFavRatio3D\",\"upcCommentRatio3D\",\"upcSVPRatio3D\",\"upcLPORatio3D\",\n",
    "    \"upcLikeRatio7D\",\"upcShareRatio7D\",\"upcFavRatio7D\",\"upcCommentRatio7D\",\"upcSVPRatio7D\",\"upcLPORatio7D\"\n",
    "]\n",
    "\n",
    "user_engaged_tags = [\n",
    "    \"engtag_0\",\"engtag_1\",\"engtag_2\",\"engtag_3\",\"engtag_4\",\n",
    "    \"engtag_5\",\"engtag_6\",\"engtag_7\",\"engtag_8\",\"engtag_9\",\n",
    "    \"engtag_10\",\"engtag_11\",\"engtag_12\",\"engtag_13\",\"engtag_14\",\n",
    "    \"engtag_15\",\"engtag_16\",\"engtag_17\",\"engtag_18\",\"engtag_19\",\n",
    "    \"engtag_20\",\"engtag_21\",\"engtag_22\",\"engtag_23\",\"engtag_24\",\n",
    "    \n",
    "    \"engtag_mask_0\",\"engtag_mask_1\",\"engtag_mask_2\",\"engtag_mask_3\",\"engtag_mask_4\",\n",
    "    \"engtag_mask_5\",\"engtag_mask_6\",\"engtag_mask_7\",\"engtag_mask_8\",\"engtag_mask_9\",\n",
    "    \"engtag_mask_10\",\"engtag_mask_11\",\"engtag_mask_12\",\"engtag_mask_13\",\"engtag_mask_14\",\n",
    "    \"engtag_mask_15\",\"engtag_mask_16\",\"engtag_mask_17\",\"engtag_mask_18\",\"engtag_mask_19\",\n",
    "    \"engtag_mask_20\",\"engtag_mask_21\",\"engtag_mask_22\",\"engtag_mask_23\",\"engtag_mask_24\"\n",
    "]\n",
    "\n",
    "post_sparse_features = [\n",
    "    'tagId'\n",
    "#     'sparse_features_tagId'\n",
    "]\n",
    "post_dense_features = [\n",
    "    \"pvplay_0\",\"pvplay_1\",\"pvplay_2\",\"pvplay_3\",\"pvplay_4\",\"pvplay_5\",\"pvplay_6\",\"pvplay_7\",\n",
    "    \"pvplay_8\",\"pvplay_9\",\"pvplay_10\",\"pvplay_11\",\"pvplay_12\",\"pvplay_13\",\"pvplay_14\",\"pvplay_15\",\n",
    "    \"pvplay_16\",\"pvplay_17\",\"pvplay_18\",\"pvplay_19\",\"pvplay_20\",\"pvplay_21\",\"pvplay_22\",\"pvplay_23\",\n",
    "    \"pvplay_24\",\"pvplay_25\",\"pvplay_26\",\"pvplay_27\",\"pvplay_28\",\"pvplay_29\",\"pvplay_30\",\"pvplay_31\",\"pvplay_mask\",\n",
    "    \"pfav_0\",\"pfav_1\",\"pfav_2\",\"pfav_3\",\"pfav_4\",\"pfav_5\",\"pfav_6\",\"pfav_7\",\n",
    "    \"pfav_8\",\"pfav_9\",\"pfav_10\",\"pfav_11\",\"pfav_12\",\"pfav_13\",\"pfav_14\",\"pfav_15\",\n",
    "    \"pfav_16\",\"pfav_17\",\"pfav_18\",\"pfav_19\",\"pfav_20\",\"pfav_21\",\"pfav_22\",\"pfav_23\",\n",
    "    \"pfav_24\",\"pfav_25\",\"pfav_26\",\"pfav_27\",\"pfav_28\",\"pfav_29\",\"pfav_30\",\"pfav_31\",\"pfav_mask\",\n",
    "    \"plike_0\",\"plike_1\",\"plike_2\",\"plike_3\",\"plike_4\",\"plike_5\",\"plike_6\",\"plike_7\",\n",
    "    \"plike_8\",\"plike_9\",\"plike_10\",\"plike_11\",\"plike_12\",\"plike_13\",\"plike_14\",\"plike_15\",\n",
    "    \"plike_16\",\"plike_17\",\"plike_18\",\"plike_19\",\"plike_20\",\"plike_21\",\"plike_22\",\"plike_23\",\n",
    "    \"plike_24\",\"plike_25\",\"plike_26\",\"plike_27\",\"plike_28\",\"plike_29\",\"plike_30\",\"plike_31\",\"plike_mask\",\n",
    "    \"pshare_0\",\"pshare_1\",\"pshare_2\",\"pshare_3\",\"pshare_4\",\"pshare_5\",\"pshare_6\",\"pshare_7\",\n",
    "    \"pshare_8\",\"pshare_9\",\"pshare_10\",\"pshare_11\",\"pshare_12\",\"pshare_13\",\"pshare_14\",\"pshare_15\",\n",
    "    \"pshare_16\",\"pshare_17\",\"pshare_18\",\"pshare_19\",\"pshare_20\",\"pshare_21\",\"pshare_22\",\"pshare_23\",\n",
    "    \"pshare_24\",\"pshare_25\",\"pshare_26\",\"pshare_27\",\"pshare_28\",\"pshare_29\",\"pshare_30\",\"pshare_31\",\"pshare_mask\",\n",
    "    \"postLikeRatio2h\",\"postShareRatio2h\",\"postFavRatio2h\",\"postCommentRatio2h\",\"postSVPRatio2h\",\"postLPORatio2h\",\n",
    "    \"postLikeRatio1D\",\"postShareRatio1D\",\"postFavRatio1D\",\"postCommentRatio1D\",\"postSVPRatio1D\",\"postLPORatio1D\",\n",
    "    \"pcLikeRatio2h\",\"pcShareRatio2h\",\"pcFavRatio2h\",\"pcCommentRatio2h\",\"pcSVPRatio2h\",\"pcLPORatio2h\",\n",
    "    \"pcLikeRatio1D\",\"pcShareRatio1D\",\"pcFavRatio1D\",\"pcCommentRatio1D\",\"pcSVPRatio1D\",\" pcLPORatio1D\"\n",
    "]\n",
    "\n",
    "past_post = [\"mrp\"]\n",
    "past_post_weights = [\"mrpw\"]\n",
    "\n",
    "ignore_features = [\n",
    "\n",
    "]\n",
    "\n",
    "DROPOUT = 0.4\n",
    "L2REG = 1e-4\n",
    "LR = 0.001\n",
    "\n",
    "#'''\n",
    "# change this - when using the total dataset\n",
    "batch_size = 50000\n",
    "NUM_TEST_EXAMPLES =  50000     \n",
    "#NUM_TEST_EXAMPLES = 208990\n",
    "#'''\n",
    "\n",
    "'''\n",
    "# small size testing \n",
    "batch_size = 1000\n",
    "NUM_TEST_EXAMPLES = 2000\n",
    "'''\n",
    "\n",
    "\n",
    "num_of_validations = 6\n",
    "\n",
    "test_folder = \"isp_ranker_data_17\"\n",
    "\n",
    "# model_folder = \"sc_ranker_debiasing_Hindi_video_wide_and_deep\"\n",
    "# model_folder = \"sc_ranker_debiasing_Hindi_video_wide_and_deep_popular_sampling\"\n",
    "# model_folder = \"sc_ranker_debiasing_Hindi_video_mask_net\"\n",
    "# model_folder = \"sc_ranker_debiasing_Hindi_video_mask_net_popular_sampling\"\n",
    "# model_folder = \"sc_ranker_debiasing_Hindi_video_mask_net_serial\"\n",
    "# model_folder = \"sc_ranker_debiasing_Hindi_video_mask_net_serial_popular_sampling\"\n",
    "# model_folder = \"sc_ranker_debiasing_Hindi_video_deep_cross_network\"\n",
    "# model_folder = \"sc_ranker_debiasing_Hindi_video_deep_cross_network_popular_sampling\"\n",
    "# model_folder = \"sc_ranker_debiasing_Hindi_video_deep_cross_network_serial\"\n",
    "model_folder = \"unified_signal_Hindi_video_mask_net_serial_sampled\"\n",
    "\n",
    "# model_name = \"wide_and_deep\"\n",
    "# model_name = \"wide_and_deep_popular\"\n",
    "# model_name = \"mask_net\"\n",
    "# model_name = \"mask_net_popular\"\n",
    "model_name = \"mask_net_serial\"\n",
    "# model_name = \"mask_net_serial_popular\"\n",
    "# model_name = \"deep_cross_net\"\n",
    "# model_name = \"deep_cross_net_popular\"\n",
    "# model_name = \"deep_cross_net_serial\"\n",
    "#model_name = \"deep_cross_net_serial_popular\"\n",
    "\n",
    "TESTDATA_DIR = \"gs://tpu-cg-us/Ashish_ranker/isp_ranker_data_17\"\n",
    "\n",
    "MODEL_DIR = \"gs://tpu-cg-us/\" + model_folder#'gs://tpu-cg-us/combined_model/3.14_tag/'\n",
    "# 'gs://sharechat-prod-bigquery-data/dca_ranker/v0/dca_ranker/2023/02/17/dca_ranker_2023_02_17_10_12_06_4821_hindi_video_model_unified/'\n",
    "MODEL_DIR_LOCAL = model_folder\n",
    "#os.system(f\"mkdir -p {MODEL_DIR_LOCAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "012f3465-4a96-4103-83f9-c7213be56ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distribute_input_option():\n",
    "    # Add a try...except block as OSS tensorflow_recommenders is depending on\n",
    "    # stable TF version, i.e. TF2.4.\n",
    "    try:\n",
    "        return tf.distribute.InputOptions(experimental_fetch_to_device=False)\n",
    "    except TypeError:\n",
    "        return tf.distribute.InputOptions(experimental_prefetch_to_device=False)\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class DataConfig:\n",
    "    \"\"\"Dataset config for training and evaluation.\"\"\"\n",
    "    input_path: str = ''\n",
    "    global_batch_size: int = batch_size\n",
    "    is_training: bool = True\n",
    "    dtype: str = 'float32'\n",
    "    shuffle_buffer_size: int = 1000#0\n",
    "    cycle_length: int = 8\n",
    "    sharding: bool = True\n",
    "    num_shards_per_host: int = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff1c1ee3-93c3-4f89-82ff-6cd37b8ec9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_mapping = pd.read_csv(\n",
    "    \"tagId_mapping.csv\",\n",
    "#     \"sc_ranker_debiasing-sc_ranker_debiasing_tag_index_mapping-000000000000.csv\",\n",
    "    dtype={'tagId': 'str'}\n",
    ")\n",
    "district_mapping = pd.read_csv(\n",
    "    \"userDistrict_mapping.csv\",\n",
    "#     \"sc_ranker_debiasing-sc_ranker_debiasing_district_index_mapping-000000000000.csv\",\n",
    "    dtype={'userDistrict': 'str'}\n",
    ")\n",
    "\n",
    "tag_mapping.sort_values(by='tag_index', axis=0, inplace=True)\n",
    "tag_mapping.reset_index(drop=True, inplace=True)\n",
    "district_mapping.fillna(\"null\", inplace=True)\n",
    "\n",
    "district_mapping.sort_values(by='district_index', axis=0, inplace=True)\n",
    "district_mapping.reset_index(drop=True, inplace=True)\n",
    "district_mapping.fillna(\"null\", inplace=True)\n",
    "\n",
    "tag_index = {\n",
    "    'keys': list(tag_mapping.tagId),\n",
    "    'values': list(tag_mapping.tag_index),\n",
    "}\n",
    "\n",
    "district_index = {\n",
    "    'keys': list(district_mapping.userDistrict),\n",
    "    'values': list(district_mapping.district_index),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16a637bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IspRT(tf.Module):\n",
    "    # Assume these are populated from embeddings file\n",
    "    # PostId, PostEmb, PostBias\n",
    "    def __init__(self, post_embs, post_biases, postIds):\n",
    "        self.post_embs = tf.constant(post_embs, dtype=tf.float32)\n",
    "        self.post_biases = tf.constant(post_biases, dtype=tf.float32)\n",
    "        self.postIds = tf.constant(postIds, dtype='string')\n",
    "        self.numPosts = len(postIds)\n",
    "        self.postIdToIndexTable = tf.lookup.StaticHashTable(\n",
    "            tf.lookup.KeyValueTensorInitializer(self.postIds, tf.constant(list(range(self.numPosts)), dtype='int64')),\n",
    "            default_value=-1\n",
    "        )\n",
    "\n",
    "    @tf.function\n",
    "    def getPostEmbsAndBias(self, postIds):\n",
    "        indexes = self.postIdToIndexTable.lookup(postIds) + 1\n",
    "        embs_with_sentinel = tf.concat([tf.constant([[0.0]*self.post_embs.shape[1]], dtype=\"float32\"), self.post_embs], 0)\n",
    "        bias_with_sentinel = tf.concat([tf.constant([0.0], dtype=\"float32\"), self.post_biases], 0)\n",
    "        return tf.gather(embs_with_sentinel, indexes), tf.gather(bias_with_sentinel, indexes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "241e92e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 08:06:20.740398: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-03-21 08:06:20.740461: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-21 08:06:20.740488: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ashish-cpu): /proc/driver/nvidia/version does not exist\n",
      "2023-03-21 08:06:20.740924: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_27 = pd.read_csv(\"post_embedding_topk_17.csv\", converters={\"embs\": json.loads}, dtype={\"postId\": \"str\"})\n",
    "# df_28 = pd.read_csv(\"post_embedding_topk_07.csv\", converters={\"embs\": json.loads}, dtype={\"postId\": \"str\"})\n",
    "# df_01 = pd.read_csv(\"post_embedding_topk_05.csv\", converters={\"embs\": json.loads}, dtype={\"postId\": \"str\"})\n",
    "\n",
    "model_27 = IspRT(df_27.embs.values.tolist(), df_27.bias.values, df_27.postId.values)\n",
    "# model_28 = IspRT(df_28.embs.values.tolist(), df_28.bias.values, df_28.postId.values)\n",
    "# model_01 = IspRT(df_01.embs.values.tolist(), df_01.bias.values, df_01.postId.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "150c61de-b32e-470e-8e3d-4dd56c3628bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVReader27(object):\n",
    "    def __init__(self, params, model, num_labels, field_delim=\"&\", use_fake_data=False):\n",
    "        self.params = params\n",
    "        self.model = model\n",
    "        self.num_labels = num_labels\n",
    "        self.field_delim = field_delim\n",
    "        self._use_fake_data = use_fake_data\n",
    "        \n",
    "        self.tag_index = tf.lookup.StaticHashTable(\n",
    "            tf.lookup.KeyValueTensorInitializer(tag_index['keys'], tag_index['values']),\n",
    "            default_value=0\n",
    "        )\n",
    "        \n",
    "        self.district_index = tf.lookup.StaticHashTable(\n",
    "            tf.lookup.KeyValueTensorInitializer(district_index['keys'], district_index['values']),\n",
    "            default_value=0\n",
    "        )\n",
    "    \n",
    "    def __call__(self, ctx: tf.distribute.InputContext):\n",
    "        params = self.params\n",
    "        batch_size = ctx.get_per_replica_batch_size(\n",
    "            params.global_batch_size\n",
    "        ) if ctx else params.global_batch_size\n",
    "        \n",
    "        @tf.function\n",
    "        def _parse_fn(example):\n",
    "            num_sparse_features = len(vocab_sizes)\n",
    "            meta_defaults = [''] * len(meta)\n",
    "            label_defaults = [0.0] * num_labels\n",
    "            \n",
    "            other_feat_defaults = [0.0] * (hour_feat+dayofweek+num_other_features)\n",
    "            \n",
    "            post_sparse_defaults = ['0'] * len(post_sparse_features)\n",
    "            post_dense_defaults = [-1.0] * len(post_dense_features)\n",
    "            \n",
    "            user_sparse_defaults = ['0'] * len(user_sparse_features)\n",
    "            user_dense_defaults = [-1.0] * len(user_dense_features)\n",
    "            user_engaged_tags_defaults = ['0'] * (len(user_engaged_tags)//2) + [0.0] * (len(user_engaged_tags)//2)\n",
    "            mrp = ['0']\n",
    "            mrpw = ['0']\n",
    "            \n",
    "            record_defaults =   meta_defaults+mrp+mrpw+label_defaults + \\\n",
    "                                other_feat_defaults + \\\n",
    "                                post_sparse_defaults + \\\n",
    "                                post_dense_defaults + \\\n",
    "                                user_sparse_defaults + \\\n",
    "                                user_dense_defaults + \\\n",
    "                                user_engaged_tags_defaults\n",
    "\n",
    "            fields = tf.io.decode_csv(example, record_defaults,\n",
    "                                      field_delim=self.field_delim, na_value='')\n",
    "            \n",
    "            #label = {\n",
    "            #    col_names[0]: tf.reshape(fields[0], [batch_size, 1])\n",
    "            #}\n",
    "            #label = fields[0] #tf.reshape(fields[0], [batch_size, 1])\n",
    "            offset = 0\n",
    "            \n",
    "            \n",
    "            meta_feats = {}\n",
    "            for idx in range(len(meta)):\n",
    "                if col_names[idx+offset] in ignore_features:\n",
    "                    continue\n",
    "                meta_feats[col_names[idx+offset]] = fields[idx+offset]\n",
    "            offset += len(meta)\n",
    "            \n",
    "            features = {'time': {}, 'sparse_features': {}, 'meta': meta_feats}\n",
    "            d={}\n",
    "            past_post_emb = []\n",
    "            for idx in range(len(past_post)):\n",
    "                if col_names[idx+offset] in ignore_features:\n",
    "                    continue\n",
    "#                 print(\"fields[idx + offset] \",fields[idx + offset])\n",
    "                postIds = tf.strings.split(fields[idx + offset], sep=\",\")\n",
    "#                 print(\"postIds \",postIds)\n",
    "#                 print(\"model_21.getPostEmbsAndBias(fields[idx + offset]) \",model_21.getPostEmbsAndBias(fields[idx + offset]))\n",
    "                recent_seq_embs, recent_seq_biases = self.model.getPostEmbsAndBias(postIds)\n",
    "                ffm_seq_embs = tf.concat([recent_seq_embs,tf.expand_dims(recent_seq_biases, axis=-1)],axis=-1)\n",
    "                d['mrp'] = ffm_seq_embs\n",
    "                past_post_emb.append(ffm_seq_embs)\n",
    "            print(\"past_post_emb \",d['mrp'].shape)\n",
    "            offset += 1#len(past_post)\n",
    "        \n",
    "            \n",
    "            past_post_emb_wt = []\n",
    "            for idx in range(len(past_post_weights)):\n",
    "                if col_names[idx+offset] in ignore_features:\n",
    "                    continue\n",
    "#                 seq = tf.keras.preprocessing.sequence.pad_sequences(fields[idx+offset],60)\n",
    "                str_weights = tf.strings.split(fields[idx+offset], sep=\",\")\n",
    "                weights = tf.strings.to_number(str_weights, tf.float32)\n",
    "                d['mrpw'] = tf.expand_dims(weights,axis=-1)#fields[idx+offset], axis=-1)#tf.stack(past_post_emb_wt, axis=1)\n",
    "            print(\"shape features['mrp'] \",d['mrp'].shape)\n",
    "            print(\"shape features['mrpw'] \",d['mrpw'].shape)\n",
    "            features['mrp_mrpw'] = tf.reshape(tf.math.divide(tf.math.reduce_sum((d['mrp'] * d['mrpw']).to_tensor(), axis=1), 26),(batch_size,65))\n",
    "#             tf.reshape((d['mrp'] * d['mrpw']).to_tensor(),(batch_size,65))#tf.stack(d['mrp'] * d['mrpw'], axis=1)#, (-1,1))#tf.tensordot(features['mrpw'],features['mrp'],axes=0)\n",
    "            print(\"mrp_mrpw shape \",features['mrp_mrpw'].shape)\n",
    "            offset += 1#len(past_post_weights)\n",
    "            \n",
    "#             isp_label = tf.cast(fields[offset+0],tf.float32)\n",
    "#             print(\"isp col_names \",col_names[offset+0])\n",
    "#             offset+= 1\n",
    "            \n",
    "            label = tf.cast(fields[offset+0], tf.float32)\n",
    "            print(\"label col_names \",col_names[offset+0])\n",
    "            offset += num_labels\n",
    "\n",
    "            for idx in range(hour_feat+dayofweek+num_other_features):\n",
    "                if col_names[idx+offset] in ignore_features:\n",
    "                    continue\n",
    "                if col_names[idx+offset] in ('hour', 'dayofweek'):\n",
    "                    features['time'][col_names[idx+offset]] = tf.cast(fields[idx+offset], tf.int32)\n",
    "                else:\n",
    "                    features['time'][col_names[idx+offset]] = tf.cast(tf.expand_dims(fields[idx+offset], axis=-1), tf.float32)\n",
    "            offset += hour_feat+dayofweek+num_other_features\n",
    "            \n",
    "            for idx in range(len(post_sparse_features)):\n",
    "                if col_names[idx+offset] in ignore_features:\n",
    "                    continue\n",
    "                    \n",
    "                if col_names[idx+offset].endswith(\"tagId\"):\n",
    "                    features['sparse_features'][col_names[idx+offset]] = self.tag_index.lookup(fields[idx+offset])\n",
    "                else:\n",
    "                    features['sparse_features'][col_names[idx+offset]] = fields[idx+offset]\n",
    "            print(\"features['sparse_features']['tagId'] post \",features['sparse_features']['tagId'])\n",
    "            offset += len(post_sparse_features)\n",
    "\n",
    "            feat = []\n",
    "            post_embed = []\n",
    "            for idx in range(len(post_dense_features)):\n",
    "                if col_names[idx+offset] in ignore_features:\n",
    "                    continue\n",
    "                if col_names[idx+offset].startswith('pvplay') or col_names[idx+offset].startswith('pfav') or col_names[idx+offset].startswith('plike') or col_names[idx+offset].startswith('pshare'):\n",
    "                    post_embed.append(fields[idx + offset])\n",
    "                feat.append(fields[idx + offset])\n",
    "            features['post_dense_features'] = tf.stack(feat, axis=1)#fields[offset]\n",
    "            features['post_embed'] = tf.stack(post_embed, axis=1)#fields[offset+1]\n",
    "            print(\"shape features['post_embed'] \",features['post_embed'].shape)\n",
    "            offset += len(post_dense_features)\n",
    "            \n",
    "            \n",
    "            for idx in range(len(user_sparse_features)):\n",
    "                if col_names[idx+offset] in ignore_features:\n",
    "                    continue\n",
    "                if col_names[idx+offset] == \"userDistrict\":\n",
    "                    features['sparse_features'][col_names[idx+offset]] = self.district_index.lookup(fields[idx+offset])\n",
    "                else:\n",
    "                    features['sparse_features'][col_names[idx+offset]] = fields[idx+offset]\n",
    "            offset += len(user_sparse_features)\n",
    "            \n",
    "            feat = []\n",
    "            user_embed = []\n",
    "            for idx in range(len(user_dense_features)):\n",
    "                if col_names[idx+offset] in ignore_features:\n",
    "                    continue\n",
    "                if col_names[idx+offset].startswith('uvplay') or col_names[idx+offset].startswith('ufav') or col_names[idx+offset].startswith('ulike') or col_names[idx+offset].startswith('ushare'):\n",
    "                    user_embed.append(fields[idx + offset])\n",
    "                feat.append(fields[idx + offset])\n",
    "            features['user_dense_features'] = tf.stack(feat, axis=1)\n",
    "            features['user_embed'] = tf.stack(user_embed, axis=1)\n",
    "            print(\"shape features['user_embed'] \",features['user_embed'])\n",
    "            offset += len(user_dense_features)\n",
    "            \n",
    "            \n",
    "            eng_tags_mask = []\n",
    "            eng_tags = []\n",
    "            for idx in range(len(user_engaged_tags)):\n",
    "                if col_names[idx+offset] in ignore_features:\n",
    "                    continue\n",
    "                if 'mask' in col_names[idx+offset]:\n",
    "                    eng_tags_mask.append(fields[idx + offset])\n",
    "                else:\n",
    "                    eng_tags.append(self.tag_index.lookup(fields[idx + offset]))\n",
    "            features['sparse_features']['eng_tags'] = tf.stack(eng_tags, axis=1)\n",
    "            features['eng_tags_mask'] = tf.stack(eng_tags_mask, axis=1)\n",
    "            print(\"features['eng_tags_mask'] \",features['eng_tags_mask'].shape)\n",
    "            offset += len(user_engaged_tags)\n",
    "            print(\"offset is \",offset)\n",
    "            \n",
    "            return features, label\n",
    "        \n",
    "        filenames = tf.data.Dataset.list_files(params.input_path, shuffle=False)\n",
    "        \n",
    "        if params.sharding and ctx and ctx.num_input_pipelines > 1:\n",
    "            filenames = filenames.shard(ctx.num_input_pipelines, ctx.input_pipeline_id)\n",
    "            \n",
    "        num_shards_per_host = 1\n",
    "        if params.sharding:\n",
    "            num_shards_per_host = params.num_shards_per_host\n",
    "\n",
    "        def make_dataset(shard_index):\n",
    "            filenames_for_shard = filenames.shard(num_shards_per_host, shard_index)\n",
    "            dataset = tf.data.TextLineDataset(filenames_for_shard)\n",
    "            if params.is_training:\n",
    "                dataset = dataset.shuffle(params.shuffle_buffer_size)\n",
    "                dataset = dataset.repeat()\n",
    "            dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "            dataset = dataset.map(_parse_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "            \n",
    "            \n",
    "            return dataset\n",
    "        indices = tf.data.Dataset.range(num_shards_per_host)\n",
    "        dataset = indices.interleave(\n",
    "            map_func=make_dataset,\n",
    "            cycle_length=params.cycle_length,\n",
    "            num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "        )\n",
    "        dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "        if self._use_fake_data:\n",
    "            dataset = dataset.take(1).cache().repeat()\n",
    "            \n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0820984a-6ec6-46c2-bef8-758b01e99f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://tpu-cg-us/Ashish_ranker/isp_ranker_data_17'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TESTDATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "848ef4c5-d539-46db-8568-5969e92af72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past_post_emb  (None, None, 65)\n",
      "shape features['mrp']  (None, None, 65)\n",
      "shape features['mrpw']  (None, None, 1)\n",
      "mrp_mrpw shape  (50000, 65)\n",
      "label col_names  unified_signal\n",
      "features['sparse_features']['tagId'] post  Tensor(\"None_Lookup/LookupTableFindV2:0\", shape=(50000,), dtype=int32)\n",
      "shape features['post_embed']  (50000, 132)\n",
      "shape features['user_embed']  Tensor(\"stack_7:0\", shape=(50000, 132), dtype=float32)\n",
      "features['eng_tags_mask']  (50000, 25)\n",
      "offset is  391\n",
      "test_steps: 1\n"
     ]
    }
   ],
   "source": [
    "test_params = DataConfig(\n",
    "    input_path=f'{TESTDATA_DIR}/*',\n",
    "    is_training=False,\n",
    "    sharding=False\n",
    ")\n",
    "test_dataset_callable = CSVReader27(\n",
    "    params=test_params,\n",
    "    num_labels=num_labels,\n",
    "    model=model_27\n",
    ")\n",
    "\n",
    "test_dataset = strategy.distribute_datasets_from_function(\n",
    "    dataset_fn=test_dataset_callable,\n",
    "    options=create_distribute_input_option()\n",
    ")\n",
    "\n",
    "test_steps = NUM_TEST_EXAMPLES // batch_size\n",
    "\n",
    "print(f\"test_steps: {test_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a9aa641-bde4-462c-b7f1-8067b569e686",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskNetModelSerial(tfrs.models.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rescale_factor = 2.0\n",
    "        \n",
    "        self.tag_embedding = tf.keras.layers.Embedding(\n",
    "                input_dim=vocab_sizes['tagId'],\n",
    "                output_dim=embedding_dims['tagId'],\n",
    "                input_length=1\n",
    "        )\n",
    "        self.eng_tag_embedding = tf.keras.layers.Embedding(\n",
    "                input_dim=vocab_sizes['tagId'],\n",
    "                output_dim=embedding_dims['tagId'],\n",
    "                input_length=25\n",
    "        )\n",
    "\n",
    "        self.district_embedding = tf.keras.layers.Embedding(\n",
    "                input_dim=vocab_sizes['userDistrict'],\n",
    "                output_dim=embedding_dims['userDistrict'],\n",
    "                input_length=1\n",
    "        )\n",
    "        \n",
    "        with tf.compat.v1.variable_scope(\"MaskBlock_time\"):\n",
    "            self.time_mask = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(\n",
    "                  units=int(feature_shapes['time']*self.rescale_factor),\n",
    "                  kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.L2(L2REG),\n",
    "                  activation=\"relu\"\n",
    "                ),\n",
    "                tf.keras.layers.Dense(\n",
    "                  units=feature_shapes['time'],\n",
    "                  kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.L2(L2REG),\n",
    "                )\n",
    "            ], name=\"InstanceGuidedMask_time\")\n",
    "            self.time_norm = tf.keras.layers.LayerNormalization()\n",
    "            self.time_mask_emb = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(\n",
    "                  units=feature_shapes['user_embed'] + feature_shapes['userDistrict'],\n",
    "                  kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.L2(L2REG),\n",
    "                ),\n",
    "                tf.keras.layers.LayerNormalization()\n",
    "            ], name=\"MaskBlock_time\")\n",
    "            \n",
    "        with tf.compat.v1.variable_scope(\"MaskBlock_user_sparse\"):\n",
    "            self.user_sparse_mask = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(\n",
    "                  units=int((feature_shapes['user_embed'] + feature_shapes['userDistrict'])\n",
    "                            *self.rescale_factor),\n",
    "                  kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.L2(L2REG),\n",
    "                  activation=\"relu\"\n",
    "                ),\n",
    "                tf.keras.layers.Dense(\n",
    "                  units=(feature_shapes['user_embed'] + feature_shapes['userDistrict']),\n",
    "                  kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.L2(L2REG),\n",
    "                )\n",
    "            ], name=\"InstanceGuidedMask_user_sparse\")\n",
    "            self.user_sparse_mask_emb = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(\n",
    "                  units=feature_shapes['eng_tags'],\n",
    "                  kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.L2(L2REG),\n",
    "                ),\n",
    "                tf.keras.layers.LayerNormalization()\n",
    "            ], name=\"MaskBlock_user_sparse\")\n",
    "            \n",
    "        with tf.compat.v1.variable_scope(\"MaskBlock_user_tags\"):\n",
    "            self.user_tags_mask = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(\n",
    "                  units=int(feature_shapes['eng_tags']*self.rescale_factor),\n",
    "                  kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.L2(L2REG),\n",
    "                  activation=\"relu\"\n",
    "                ),\n",
    "                tf.keras.layers.Dense(\n",
    "                  units=feature_shapes['eng_tags'],\n",
    "                  kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.L2(L2REG),\n",
    "                )\n",
    "            ], name=\"InstanceGuidedMask_user_tags\")\n",
    "            self.user_tags_mask_emb = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(\n",
    "                  units=feature_shapes['user_dense_features'],\n",
    "                  kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.L2(L2REG),\n",
    "                ),\n",
    "                tf.keras.layers.LayerNormalization()\n",
    "            ], name=\"MaskBlock_user_tags\")\n",
    "        \n",
    "        with tf.compat.v1.variable_scope(\"MaskBlock_user_dense\"):\n",
    "            self.user_dense_mask = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(\n",
    "                  units=int(feature_shapes['user_dense_features']*self.rescale_factor),\n",
    "                  kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.L2(L2REG),\n",
    "                  activation=\"relu\"\n",
    "                ),\n",
    "                tf.keras.layers.Dense(\n",
    "                  units=feature_shapes['user_dense_features'],\n",
    "                  kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.L2(L2REG),\n",
    "                )\n",
    "            ], name=\"InstanceGuidedMask_user_dense\")\n",
    "            self.user_dense_mask_emb = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(\n",
    "                  units=(feature_shapes['post_embed'] + feature_shapes['tagId']),\n",
    "                  kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.L2(L2REG),\n",
    "                ),\n",
    "                tf.keras.layers.LayerNormalization()\n",
    "            ], name=\"MaskBlock_user_dense\")\n",
    "            \n",
    "        with tf.compat.v1.variable_scope(\"MaskBlock_post_sparse\"):\n",
    "            self.post_sparse_mask = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(\n",
    "                  units=int((feature_shapes['post_embed'] + feature_shapes['tagId'])\n",
    "                            *self.rescale_factor),\n",
    "                  kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.L2(L2REG),\n",
    "                  activation=\"relu\"\n",
    "                ),\n",
    "                tf.keras.layers.Dense(\n",
    "                  units=(feature_shapes['post_embed'] + feature_shapes['tagId']),\n",
    "                  kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.L2(L2REG),\n",
    "                )\n",
    "            ], name=\"InstanceGuidedMask_post_sparse\")\n",
    "            self.post_sparse_mask_emb = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(\n",
    "                  units=feature_shapes['post_dense_features'],\n",
    "                  kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.L2(L2REG),\n",
    "                ),\n",
    "                tf.keras.layers.LayerNormalization()\n",
    "            ], name=\"MaskBlock_post_sparse\")\n",
    "        \n",
    "        with tf.compat.v1.variable_scope(\"MaskBlock_post_dense\"):\n",
    "            self.post_dense_mask = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(\n",
    "                  units=int(feature_shapes['post_dense_features']*self.rescale_factor),\n",
    "                  kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.L2(L2REG),\n",
    "                  activation=\"relu\"\n",
    "                ),\n",
    "                tf.keras.layers.Dense(\n",
    "                  units=feature_shapes['post_dense_features'],\n",
    "                  kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.L2(L2REG),\n",
    "                )\n",
    "            ], name=\"InstanceGuidedMask_post_dense\")\n",
    "            self.post_dense_mask_emb = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(\n",
    "                  units=feature_shapes['post_dense_features'],\n",
    "                  kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.L2(L2REG),\n",
    "                ),\n",
    "                tf.keras.layers.LayerNormalization()\n",
    "            ], name=\"MaskBlock_post_dense\")\n",
    "        with tf.compat.v1.variable_scope(\"MaskBlock_recent_post_emb_weights\"):\n",
    "            self.past_post_dense_mask = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(\n",
    "                  units=int((feature_shapes['mrp_mrpw'])\n",
    "                            *self.rescale_factor),\n",
    "                  kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.L2(L2REG),\n",
    "                  activation=\"relu\"\n",
    "                ),\n",
    "                tf.keras.layers.Dense(\n",
    "                  units=(feature_shapes['post_dense_features']),\n",
    "                  kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.L2(L2REG),\n",
    "                )\n",
    "            ], name=\"InstanceGuidedMask_recent_post_dense\")\n",
    "            self.past_post_dense_mask_emb = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(\n",
    "                  units=feature_shapes['mrp_mrpw'],\n",
    "                  kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.L2(L2REG),\n",
    "                ),\n",
    "                tf.keras.layers.LayerNormalization()\n",
    "            ], name=\"MaskBlock_recent_post_dense\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        with tf.compat.v1.variable_scope(\"ClassificationTower\"):\n",
    "            self.classification_tower = tf.keras.Sequential([\n",
    "              tf.keras.layers.Dense(\n",
    "                  units=1,\n",
    "                  kernel_initializer=tf.keras.initializers.VarianceScaling(),\n",
    "                  kernel_regularizer=tf.keras.regularizers.L2(L2REG),\n",
    "              )\n",
    "            ])\n",
    "\n",
    "        self.final_activation = tf.keras.layers.Activation('relu')\n",
    "        \n",
    "        self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            #loss=tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE),\n",
    "            loss=tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE),\n",
    "            metrics=[\n",
    "#                     tf.keras.metrics.AUC(name=\"auc\"),\n",
    "#                     tf.keras.metrics.AUC(curve=\"PR\", name=\"pr-auc\"),\n",
    "                    # tf.keras.metrics.Precision(name=\"precision\"),\n",
    "                    # tf.keras.metrics.Recall(name=\"recall\"),\n",
    "                    # tf.keras.metrics.TruePositives(name=\"TP\"),\n",
    "                    # tf.keras.metrics.FalsePositives(name=\"FP\"),\n",
    "                    # tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy'),\n",
    "                    tf.keras.metrics.Accuracy(name='accuracy'),\n",
    "                    tf.keras.metrics.CosineSimilarity(name='cosine_similarity', axis=-1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        \n",
    "    def compute_loss(self, inputs, training=False) -> tf.Tensor:\n",
    "        loss = 0\n",
    "        if len(inputs) == 2:\n",
    "            features, labels = inputs\n",
    "            rating_predictions = self(features)\n",
    "            loss = self.task(labels=labels, predictions=rating_predictions)\n",
    "        elif len(inputs) == 3:\n",
    "            features, labels, sample_weight = inputs\n",
    "            rating_predictions = self(features)\n",
    "            loss = self.task(labels=labels, predictions=rating_predictions, sample_weight=sample_weight)\n",
    "        \n",
    "        loss = tf.reduce_mean(loss)\n",
    "        return tf.cast(loss,tf.float32) / tf.distribute.get_strategy().num_replicas_in_sync\n",
    "    \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        sparse_features = inputs[\"sparse_features\"]\n",
    "#         if sparse_features['tagId']>4000:\n",
    "#             sparse_features['tagId'] = 0\n",
    "        tag_embed = self.tag_embedding(sparse_features['tagId'])\n",
    "        eng_tag_embed = self.tag_embedding(sparse_features['eng_tags'])\n",
    "        sequence_length = tf.math.reduce_sum(inputs['eng_tags_mask'], axis=1, keepdims=True) + 0.0001\n",
    "#         print(\"tagId shape \",tag_embed.shape,\" eng_tag_embed shape \",eng_tag_embed.shape)\n",
    "#         print(\"sequence_length \",sequence_length)\n",
    "        \n",
    "        eng_tag_embed = tf.math.divide(tf.math.reduce_sum(eng_tag_embed, axis=1), sequence_length)\n",
    "        district_embed = self.district_embedding(sparse_features['userDistrict'])\n",
    "\n",
    "        hour = tf.one_hot(inputs['time']['hour'], 24)\n",
    "        dayofweek = tf.one_hot(inputs['time']['dayofweek'], 7)\n",
    "        time = tf.keras.layers.Concatenate(axis=-1)([\n",
    "            hour, dayofweek,\n",
    "            inputs['time']['is_weekend'],\n",
    "            inputs['time']['is_morning'],\n",
    "            inputs['time']['is_afternoon'],\n",
    "            inputs['time']['is_evening'],\n",
    "            inputs['time']['is_night'],\n",
    "        ])\n",
    "        user_sparse = tf.keras.layers.Concatenate()([inputs['user_embed'], district_embed])\n",
    "        post_sparse = tf.keras.layers.Concatenate()([inputs['post_embed'], tag_embed])\n",
    "        user_dense = inputs['user_dense_features']\n",
    "        post_dense = inputs['post_dense_features']\n",
    "        mrpw_dense = inputs['mrp_mrpw']\n",
    "#         print(\"user_sparse shape \",user_sparse.shape,\" post_sparse shape \",post_sparse.shape,\" user_dense shape \",user_dense.shape)\n",
    "#         print(\"post_dense shape \",post_dense.shape)\n",
    "#         print(\"mrpw_dense \",mrpw_dense.shape)\n",
    "        \n",
    "        time_norm = self.time_norm(time)\n",
    "        time_mask = self.time_mask(time)\n",
    "        time_mask_emb = self.time_mask_emb(tf.keras.layers.Multiply()([time_norm, time_mask]))\n",
    "        \n",
    "        \n",
    "        #user_sparse_norm = self.user_sparse_norm(user_sparse)\n",
    "        user_sparse_mask = self.user_sparse_mask(user_sparse)\n",
    "        user_sparse_mask_emb = self.user_sparse_mask_emb(tf.keras.layers.Multiply()([time_mask_emb, user_sparse_mask]))\n",
    "        \n",
    "#         user_tags_norm = self.user_tags_norm(eng_tag_embed)\n",
    "        user_tags_mask = self.user_tags_mask(eng_tag_embed)\n",
    "        user_tags_mask_emb = self.user_tags_mask_emb(tf.keras.layers.Multiply()([user_sparse_mask_emb, user_tags_mask]))\n",
    "        \n",
    "#         user_dense_norm = self.user_dense_norm(user_dense)\n",
    "        user_dense_mask = self.user_dense_mask(user_dense)\n",
    "        user_dense_mask_emb = self.user_dense_mask_emb(tf.keras.layers.Multiply()([user_tags_mask_emb, user_dense_mask]))\n",
    "        \n",
    "        \n",
    "#         post_sparse_norm = self.post_sparse_norm(post_sparse)\n",
    "        post_sparse_mask = self.post_sparse_mask(post_sparse)\n",
    "        post_sparse_mask_emb = self.post_sparse_mask_emb(tf.keras.layers.Multiply()([user_dense_mask_emb, post_sparse_mask]))\n",
    "        \n",
    "#         post_dense_norm = self.post_dense_norm(post_dense)\n",
    "        post_dense_mask = self.post_dense_mask(post_dense)\n",
    "        post_dense_mask_emb = self.post_dense_mask_emb(tf.keras.layers.Multiply()([post_sparse_mask_emb, post_dense_mask]))\n",
    "#         print(\"user_dense_mask \",user_dense_mask.shape,\" user_dense_mask_emb \",user_dense_mask_emb.shape)\n",
    "#         print(\"post_sparse_mask \",post_sparse_mask.shape,\" post_sparse_mask_emb \",post_sparse_mask_emb.shape)\n",
    "#         print(\"post_dense_mask \",post_dense_mask.shape,\" post_dense_mask_emb \",post_dense_mask_emb.shape)\n",
    "        \n",
    "        past_post_dense_mask = self.past_post_dense_mask(mrpw_dense)\n",
    "        past_post_dense_mask_emb = self.past_post_dense_mask_emb(tf.keras.layers.Multiply()([post_dense_mask_emb, past_post_dense_mask]))\n",
    "#         print(\"past_post_dense_mask \",past_post_dense_mask.shape,\" past_post_dense_mask_emb \",past_post_dense_mask_emb.shape)\n",
    "        \n",
    "        vector = past_post_dense_mask_emb#post_dense_mask_emb#past_post_dense_mask_emb#post_dense_mask_emb#\n",
    "        \n",
    "        logits = self.classification_tower(vector)\n",
    "        \n",
    "        prediction = self.final_activation(logits)\n",
    "        \n",
    "        return tf.reshape(prediction, [-1])\n",
    "\n",
    "    @property\n",
    "    def embedding_trainable_variables(self) -> Sequence[tf.Variable]:\n",
    "        return [] #self.embedding_layer.trainable_variables\n",
    "\n",
    "    @property\n",
    "    def deep_trainable_variables(self) -> Sequence[tf.Variable]:\n",
    "        dense_vars = []\n",
    "        for layer in self.layers:\n",
    "#             if layer != self.embedding_layer:\n",
    "            dense_vars.extend(layer.trainable_variables)\n",
    "        return dense_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c29e0206-d3df-4cea-a691-ede95f3ffdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_shapes = {\n",
    "    'time': 36,\n",
    "    'post_dense_features': 156,\n",
    "    'user_dense_features': 163,\n",
    "    'user_embed': 132,\n",
    "    'post_embed': 132,\n",
    "    'tagId': embedding_dims['tagId'],\n",
    "    'userDistrict': embedding_dims['userDistrict'],\n",
    "    'eng_tags': embedding_dims['tagId'],\n",
    "    'mrp_mrpw': 65\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa100878-fc6e-45f6-b8ec-0069ec694b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    # embedding_optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
    "    # deep_optimizer = tf.keras.optimizers.Adagrad(lr=0.1)\n",
    "\n",
    "    \n",
    "    model = MaskNetModelSerial()\n",
    "\n",
    "    # optimizer = tfrs.experimental.optimizers.CompositeOptimizer([\n",
    "    #     (embedding_optimizer, lambda: model.embedding_trainable_variables),\n",
    "    #     (deep_optimizer, lambda: model.deep_trainable_variables),\n",
    "    # ])\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=0.0005)\n",
    "    model.load_weights(\"gs://tpu-cg-us/unified_signal_Hindi_video_mask_net_serial_sampled/checkpoints/check_iter_mnet2\")\n",
    "#     model.load_weights(MODEL_DIR + 'hindi_video_model_unified/' + 'export/variables/variables')\n",
    "    \n",
    "#     model.compile(optimizer)\n",
    "    #model.load_weights('gs://deep-ctr/devansh_production/checkpoints/my_checkpoint2')\n",
    "    #model = tf.keras.models.load_model('gs://deep-ctr/devansh_production/models2/')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bea7019",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    \n",
    "    prod_model = MaskNetModelSerial()\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(lr=0.0005)\n",
    "    MODEL_DIR = \"gs://sharechat-prod-bigquery-data/dca_ranker/v0/dca_ranker/2023/03/10/dca_ranker_2023_03_10_10_11_47_8810_\"\n",
    "#     model.load_weights(MODEL_DIR + '/checkpoints/check_iter_mnet2')\n",
    "    prod_model.load_weights(MODEL_DIR + 'hindi_video_model_unified/' + 'export/variables/variables')\n",
    "    \n",
    "    prod_model.compile(optimizer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f578865-568f-4611-8d09-97d80f148cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, example in enumerate(test_dataset):\n",
    "    pred = model(example[0])\n",
    "    print(pred)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f980e428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken 71.39 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start=time.perf_counter()\n",
    "\n",
    "\n",
    "pred_df = {\n",
    "    'userId': [],\n",
    "    'postId': [],\n",
    "#     'lang': [],\n",
    "    'groundtruth': [],\n",
    "    'groundtruth2': [],\n",
    "    'groundtruth3': [],\n",
    "    'groundtruth4': [],\n",
    "    'prediction': [],\n",
    "    'production_model_prediction_unified': [],\n",
    "    'production_model_prediction': [],\n",
    "}\n",
    "\n",
    "prediction = []\n",
    "groundtruth = []\n",
    "production_model_prediction = []\n",
    "\n",
    "\n",
    "for ind, example in enumerate(test_dataset):      \n",
    "    pred = model(example[0])\n",
    "    pred_df['userId'] += list(example[0]['meta']['userId'].numpy().astype('str'))\n",
    "    pred_df['postId'] += list(example[0]['meta']['postId'].numpy().astype('str'))\n",
    "#     pred_df['lang'] += list(example[0]['meta']['lang'].numpy().astype('str'))\n",
    "\n",
    "    #pred_df['groundtruth'] += list(example[1].numpy())\n",
    "    pred_df['groundtruth'] += list(example[0]['meta']['video_play'].numpy().astype('float32'))\n",
    "    pred_df['groundtruth2'] += list(example[0]['meta']['likes'].numpy().astype('float32'))\n",
    "    pred_df['groundtruth3'] += list(example[0]['meta']['shares'].numpy().astype('float32'))\n",
    "    pred_df['groundtruth4'] += list(example[0]['meta']['favs'].numpy().astype('float32'))\n",
    "    pred_df['prediction'] += list(pred.numpy())\n",
    "    pred_df['production_model_prediction_unified'] += list(example[0]['meta']['unified_signal1'].numpy().astype('float32'))\n",
    "    pred_df['production_model_prediction'] += list(example[0]['meta']['combined_score'].numpy().astype('float32'))\n",
    "    \n",
    "    if ind > test_steps:\n",
    "        break\n",
    "    \n",
    "end=time.perf_counter()\n",
    "print(f\"time taken {round(end-start,2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac01efa8-74e2-4743-8fab-c6d2ba82ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start=time.perf_counter()\n",
    "\n",
    "\n",
    "pred_df_prod = {\n",
    "    'userId': [],\n",
    "    'postId': [],\n",
    "#     'lang': [],\n",
    "    'groundtruth': [],\n",
    "    'prediction': [],\n",
    "    'production_model_prediction_unified': [],\n",
    "    'production_model_prediction': [],\n",
    "}\n",
    "\n",
    "prediction = []\n",
    "groundtruth = []\n",
    "production_model_prediction = []\n",
    "\n",
    "\n",
    "for ind, example in enumerate(test_dataset):      \n",
    "    pred = prod_model(example[0])\n",
    "    pred_df_prod['userId'] += list(example[0]['meta']['userId'].numpy().astype('str'))\n",
    "    pred_df_prod['postId'] += list(example[0]['meta']['postId'].numpy().astype('str'))\n",
    "#     pred_df['lang'] += list(example[0]['meta']['lang'].numpy().astype('str'))\n",
    "\n",
    "    #pred_df['groundtruth'] += list(example[1].numpy())\n",
    "    pred_df_prod['groundtruth'] += list(example[0]['meta']['video_play'].numpy().astype('float32'))\n",
    "    pred_df_prod['prediction'] += list(pred.numpy())\n",
    "    pred_df_prod['production_model_prediction_unified'] += list(example[0]['meta']['unified_signal1'].numpy().astype('float32'))\n",
    "    pred_df_prod['production_model_prediction'] += list(example[0]['meta']['combined_score'].numpy().astype('float32'))\n",
    "    \n",
    "    if ind > test_steps:\n",
    "        break\n",
    "    \n",
    "end=time.perf_counter()\n",
    "print(f\"time taken {round(end-start,2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e43f4336-d74e-436f-af4f-6ca21f617e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DCG(labels, perm, top=10):\n",
    "    result = 0.0\n",
    "    for i in range(min(top, len(perm))):\n",
    "        result += labels[perm[i]] / np.log(i+2)\n",
    "    return result\n",
    "def NDCG(labels, preds, top=10):\n",
    "    args = np.argsort(-preds)\n",
    "    iargs = np.argsort(-labels)\n",
    "    iDCG = DCG(labels, iargs, top=top)\n",
    "    if iDCG < 1e-3:\n",
    "        return 0.0, 0\n",
    "    return DCG(labels, args, top=top) / iDCG, 1\n",
    "\n",
    "def calc_NDCG(df, preds_field, label_field=\"groundtruth\", top=10):\n",
    "    dfg = df.groupby(\"userId\")\n",
    "    result = 0\n",
    "    count = 0\n",
    "    for _, group in dfg:\n",
    "        if len(group) <= 1:\n",
    "            continue\n",
    "        labels = group[label_field].values\n",
    "        preds = group[preds_field].values\n",
    "        result_a, count_a = NDCG(labels, preds, top=top)\n",
    "        result += result_a\n",
    "        count += count_a\n",
    "    result /= count\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f66c7e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'userId': ['2173758363',\n",
       "  '2723484960',\n",
       "  '342304182',\n",
       "  '2629707858',\n",
       "  '1184167872',\n",
       "  '2714126634',\n",
       "  '542250846',\n",
       "  '77757318',\n",
       "  '1399834782',\n",
       "  '1273421601',\n",
       "  '2348258778',\n",
       "  '2414520702',\n",
       "  '1861668846',\n",
       "  '2416267008',\n",
       "  '1922779476',\n",
       "  '1895404212',\n",
       "  '1158547392',\n",
       "  '1312618122',\n",
       "  '2557898856',\n",
       "  '758651616',\n",
       "  '1715402097',\n",
       "  '2252921409',\n",
       "  '484292826',\n",
       "  '2581512804',\n",
       "  '1531319373',\n",
       "  '1184397804',\n",
       "  '469741590',\n",
       "  '1765411497',\n",
       "  '827689491',\n",
       "  '356692806',\n",
       "  '1044160029',\n",
       "  '976921992',\n",
       "  '2669083668',\n",
       "  '1551462876',\n",
       "  '1479893904',\n",
       "  '2239385967',\n",
       "  '2202384537',\n",
       "  '512129682',\n",
       "  '839635029',\n",
       "  '1554879573',\n",
       "  '1199513961',\n",
       "  '2409264261',\n",
       "  '1242312345',\n",
       "  '857236005',\n",
       "  '700815978',\n",
       "  '2681040726',\n",
       "  '1792226565',\n",
       "  '522991485',\n",
       "  '1357743348',\n",
       "  '1691369037',\n",
       "  '2348258778',\n",
       "  '2547449415',\n",
       "  '1876576311',\n",
       "  '842071752',\n",
       "  '1275690699',\n",
       "  '2329801434',\n",
       "  '794717847',\n",
       "  '2768992812',\n",
       "  '2565507600',\n",
       "  '1169033904',\n",
       "  '1486424331',\n",
       "  '1357743348',\n",
       "  '2593570383',\n",
       "  '976921992',\n",
       "  '2651282424',\n",
       "  '1589024043',\n",
       "  '1796286708',\n",
       "  '685811601',\n",
       "  '2508474906',\n",
       "  '1361464308',\n",
       "  '1838274399',\n",
       "  '1546614603',\n",
       "  '1855443240',\n",
       "  '1744618356',\n",
       "  '2374096959',\n",
       "  '1546614603',\n",
       "  '2699781480',\n",
       "  '850287474',\n",
       "  '1842539517',\n",
       "  '531146835',\n",
       "  '2069818272',\n",
       "  '2634223671',\n",
       "  '500291838',\n",
       "  '6408180',\n",
       "  '2183592015',\n",
       "  '2723484960',\n",
       "  '1837293435',\n",
       "  '2382417639',\n",
       "  '2189259783',\n",
       "  '1739148606',\n",
       "  '2415076713',\n",
       "  '492852789',\n",
       "  '201088818',\n",
       "  '1087714026',\n",
       "  '707330187',\n",
       "  '1524205827',\n",
       "  '2613468474',\n",
       "  '433457982',\n",
       "  '1287151029',\n",
       "  '1659436983',\n",
       "  '144795123',\n",
       "  '1745972334',\n",
       "  '1758321495',\n",
       "  '2479154589',\n",
       "  '685811601',\n",
       "  '1354916673',\n",
       "  '1125096804',\n",
       "  '2750730948',\n",
       "  '2577448413',\n",
       "  '1318255875',\n",
       "  '1442238093',\n",
       "  '139795218',\n",
       "  '2717445393',\n",
       "  '1698660873',\n",
       "  '486972675',\n",
       "  '144795123',\n",
       "  '1363468878',\n",
       "  '2421510669',\n",
       "  '452797173',\n",
       "  '456896970',\n",
       "  '2501470404',\n",
       "  '2366336223',\n",
       "  '436840542',\n",
       "  '2129613939',\n",
       "  '2628543960',\n",
       "  '1911017772',\n",
       "  '864804897',\n",
       "  '1854427824',\n",
       "  '2639830995',\n",
       "  '885927528',\n",
       "  '2419430949',\n",
       "  '1703530377',\n",
       "  '2060644194',\n",
       "  '512129682',\n",
       "  '2309978601',\n",
       "  '442834614',\n",
       "  '759599073',\n",
       "  '976921992',\n",
       "  '2577736566',\n",
       "  '1422250794',\n",
       "  '1586828412',\n",
       "  '1414130247',\n",
       "  '513518616',\n",
       "  '2433364659',\n",
       "  '456896970',\n",
       "  '2243199699',\n",
       "  '2174068422',\n",
       "  '1191652290',\n",
       "  '1339380621',\n",
       "  '2680985934',\n",
       "  '989956629',\n",
       "  '715041468',\n",
       "  '1228080834',\n",
       "  '1443482937',\n",
       "  '2455899219',\n",
       "  '2545101252',\n",
       "  '2722560309',\n",
       "  '1929926277',\n",
       "  '493845102',\n",
       "  '485464068',\n",
       "  '2699781480',\n",
       "  '2474509797',\n",
       "  '2666802564',\n",
       "  '806406651',\n",
       "  '436840542',\n",
       "  '920350440',\n",
       "  '1098529344',\n",
       "  '2332066545',\n",
       "  '2091540078',\n",
       "  '1484095509',\n",
       "  '1679757930',\n",
       "  '1312618122',\n",
       "  '1603269081',\n",
       "  '274334913',\n",
       "  '1960118298',\n",
       "  '1855755486',\n",
       "  '682237899',\n",
       "  '2337860286',\n",
       "  '814232007',\n",
       "  '869080977',\n",
       "  '2521958508',\n",
       "  '1164055527',\n",
       "  '835958970',\n",
       "  '1075698891',\n",
       "  '1477867743',\n",
       "  '1184397804',\n",
       "  '2504640753',\n",
       "  '830946141',\n",
       "  '785503656',\n",
       "  '1144430892',\n",
       "  '1532154069',\n",
       "  '682814070',\n",
       "  '2668843746',\n",
       "  '1232439237',\n",
       "  '160052967',\n",
       "  '2485492272',\n",
       "  '444397014',\n",
       "  '1004011713',\n",
       "  '1004011713',\n",
       "  '1061599023',\n",
       "  '1251062730',\n",
       "  '954133299',\n",
       "  '1701124173',\n",
       "  '1873826586',\n",
       "  '836355825',\n",
       "  '262582470',\n",
       "  '2240295858',\n",
       "  '1294165521',\n",
       "  '2269965357',\n",
       "  '1655883954',\n",
       "  '2690542134',\n",
       "  '1483677990',\n",
       "  '2266126461',\n",
       "  '2585265876',\n",
       "  '1212229782',\n",
       "  '842254407',\n",
       "  '1446676803',\n",
       "  '329542884',\n",
       "  '1337097582',\n",
       "  '1212229782',\n",
       "  '2494059804',\n",
       "  '1026020817',\n",
       "  '596355732',\n",
       "  '1081588653',\n",
       "  '1779410583',\n",
       "  '1463053176',\n",
       "  '2139354144',\n",
       "  '2306178000',\n",
       "  '2650448043',\n",
       "  '2306178000',\n",
       "  '2650448043',\n",
       "  '1313142264',\n",
       "  '1274787468',\n",
       "  '2719266003',\n",
       "  '2564287371',\n",
       "  '988658199',\n",
       "  '1925137521',\n",
       "  '320660010',\n",
       "  '1856065446',\n",
       "  '320660010',\n",
       "  '2551603869',\n",
       "  '723492207',\n",
       "  '1107891810',\n",
       "  '1107891810',\n",
       "  '1296873837',\n",
       "  '1721822670',\n",
       "  '2567544903',\n",
       "  '761922144',\n",
       "  '2613262608',\n",
       "  '1205508546',\n",
       "  '1392426261',\n",
       "  '1625178609',\n",
       "  '1281666942',\n",
       "  '1363862889',\n",
       "  '572695677',\n",
       "  '2331605394',\n",
       "  '59530392',\n",
       "  '59530392',\n",
       "  '1035611730',\n",
       "  '2730287763',\n",
       "  '2523642489',\n",
       "  '1310923287',\n",
       "  '2231264106',\n",
       "  '2161358640',\n",
       "  '2388100824',\n",
       "  '2388100824',\n",
       "  '1217472111',\n",
       "  '1787144931',\n",
       "  '2463948846',\n",
       "  '94137687',\n",
       "  '2705611167',\n",
       "  '1913170734',\n",
       "  '1696163418',\n",
       "  '2005623351',\n",
       "  '1439160750',\n",
       "  '2183445531',\n",
       "  '2183445531',\n",
       "  '2752825239',\n",
       "  '2761791651',\n",
       "  '464017779',\n",
       "  '1604813409',\n",
       "  '1604813409',\n",
       "  '2126676321',\n",
       "  '2112670089',\n",
       "  '2565877131',\n",
       "  '2126676321',\n",
       "  '449594469',\n",
       "  '472151745',\n",
       "  '433566261',\n",
       "  '1421865171',\n",
       "  '1856110968',\n",
       "  '172569609',\n",
       "  '2621385081',\n",
       "  '763859538',\n",
       "  '1058708664',\n",
       "  '938032677',\n",
       "  '1261779651',\n",
       "  '1584999873',\n",
       "  '2330785674',\n",
       "  '2330785674',\n",
       "  '1697917527',\n",
       "  '2323328787',\n",
       "  '2323328787',\n",
       "  '2587368429',\n",
       "  '1509901173',\n",
       "  '1234784565',\n",
       "  '2338131528',\n",
       "  '153772083',\n",
       "  '2066571486',\n",
       "  '1199866761',\n",
       "  '2466202338',\n",
       "  '2727226593',\n",
       "  '2585211750',\n",
       "  '214272135',\n",
       "  '793238022',\n",
       "  '1004232780',\n",
       "  '1004232780',\n",
       "  '1414889262',\n",
       "  '1690196724',\n",
       "  '2663379531',\n",
       "  '2524008312',\n",
       "  '1471827690',\n",
       "  '1947336489',\n",
       "  '339900930',\n",
       "  '1110263760',\n",
       "  '1144417176',\n",
       "  '734333382',\n",
       "  '802833039',\n",
       "  '2219074002',\n",
       "  '1842709338',\n",
       "  '1490667588',\n",
       "  '1776611961',\n",
       "  '1740408786',\n",
       "  '2137555620',\n",
       "  '472248144',\n",
       "  '112681179',\n",
       "  '2181002895',\n",
       "  '1228987926',\n",
       "  '1141347870',\n",
       "  '2198640060',\n",
       "  '459730368',\n",
       "  '2716618761',\n",
       "  '1934236107',\n",
       "  '2703377088',\n",
       "  '1600577361',\n",
       "  '1891257399',\n",
       "  '2218407201',\n",
       "  '848956743',\n",
       "  '606830580',\n",
       "  '2775133863',\n",
       "  '1713902499',\n",
       "  '2541041955',\n",
       "  '1925182845',\n",
       "  '64731204',\n",
       "  '1433894193',\n",
       "  '2099736063',\n",
       "  '2126906352',\n",
       "  '1934763102',\n",
       "  '1002477096',\n",
       "  '1000049769',\n",
       "  '1084686201',\n",
       "  '1144469250',\n",
       "  '1327130973',\n",
       "  '1514740923',\n",
       "  '1777543623',\n",
       "  '977689719',\n",
       "  '2546618184',\n",
       "  '550815363',\n",
       "  '550815363',\n",
       "  '2426574816',\n",
       "  '1555953642',\n",
       "  '278421363',\n",
       "  '2460596616',\n",
       "  '636587019',\n",
       "  '1053903717',\n",
       "  '1497915333',\n",
       "  '1968396480',\n",
       "  '1777873554',\n",
       "  '2705718906',\n",
       "  '2006797716',\n",
       "  '868039002',\n",
       "  '161886744',\n",
       "  '1586657448',\n",
       "  '2733897114',\n",
       "  '1588070601',\n",
       "  '2197830942',\n",
       "  '962420859',\n",
       "  '1558531593',\n",
       "  '1679743026',\n",
       "  '2554734438',\n",
       "  '1053144729',\n",
       "  '2125736118',\n",
       "  '2706467832',\n",
       "  '1775921616',\n",
       "  '2475927756',\n",
       "  '1504822878',\n",
       "  '2387903616',\n",
       "  '2398113918',\n",
       "  '1870606737',\n",
       "  '1993146435',\n",
       "  '708422301',\n",
       "  '2595310380',\n",
       "  '2474984862',\n",
       "  '71914635',\n",
       "  '1122826716',\n",
       "  '1122826716',\n",
       "  '1299671523',\n",
       "  '1269474966',\n",
       "  '1269474966',\n",
       "  '2484208503',\n",
       "  '2264227344',\n",
       "  '123310080',\n",
       "  '1299671523',\n",
       "  '2097520407',\n",
       "  '2183247963',\n",
       "  '1984058892',\n",
       "  '1503362772',\n",
       "  '1976304339',\n",
       "  '2522977191',\n",
       "  '593518833',\n",
       "  '2119128741',\n",
       "  '2522977191',\n",
       "  '1031405436',\n",
       "  '1274827392',\n",
       "  '1692740529',\n",
       "  '1966682421',\n",
       "  '2277341928',\n",
       "  '2066358132',\n",
       "  '1007609679',\n",
       "  '2086513560',\n",
       "  '81156042',\n",
       "  '2122461288',\n",
       "  '21267117',\n",
       "  '2238480738',\n",
       "  '2560361859',\n",
       "  '210698298',\n",
       "  '2542376907',\n",
       "  '1565119494',\n",
       "  '92088549',\n",
       "  '2452495923',\n",
       "  '2760479433',\n",
       "  '1542821976',\n",
       "  '1763325648',\n",
       "  '1568060019',\n",
       "  '543053439',\n",
       "  '1283533155',\n",
       "  '1779998967',\n",
       "  '1779998967',\n",
       "  '1362465423',\n",
       "  '570988674',\n",
       "  '2414405331',\n",
       "  '2608855938',\n",
       "  '1236326931',\n",
       "  '2773912311',\n",
       "  '658811763',\n",
       "  '1642202127',\n",
       "  '2188280952',\n",
       "  '658811763',\n",
       "  '471452733',\n",
       "  '2213676846',\n",
       "  '2455989633',\n",
       "  '468446238',\n",
       "  '859489794',\n",
       "  '776120247',\n",
       "  '1431421308',\n",
       "  '2026821321',\n",
       "  '1088908533',\n",
       "  '2302929261',\n",
       "  '964322217',\n",
       "  '1286677233',\n",
       "  '817487055',\n",
       "  '2369887047',\n",
       "  '1284813054',\n",
       "  '490788126',\n",
       "  '1071594234',\n",
       "  '1508846247',\n",
       "  '2448239931',\n",
       "  '1401642144',\n",
       "  '2600770914',\n",
       "  '1199942226',\n",
       "  '1763143704',\n",
       "  '1433933946',\n",
       "  '1576500957',\n",
       "  '2130752025',\n",
       "  '2001145545',\n",
       "  '2684365218',\n",
       "  '2129103738',\n",
       "  '1838443860',\n",
       "  '152162361',\n",
       "  '2352741813',\n",
       "  '926395524',\n",
       "  '926395524',\n",
       "  '1150655472',\n",
       "  '1891712169',\n",
       "  '1101119742',\n",
       "  '1906370991',\n",
       "  '1446931710',\n",
       "  '1020539169',\n",
       "  '1076807160',\n",
       "  '2463755526',\n",
       "  '1954687401',\n",
       "  '1684819062',\n",
       "  '2178670851',\n",
       "  '1172297736',\n",
       "  '2404868517',\n",
       "  '486450414',\n",
       "  '900949806',\n",
       "  '1381139001',\n",
       "  '2469634227',\n",
       "  '826298685',\n",
       "  '1443223440',\n",
       "  '916686423',\n",
       "  '1250955135',\n",
       "  '2548449828',\n",
       "  '2137864149',\n",
       "  '1250955135',\n",
       "  '2509797591',\n",
       "  '221358420',\n",
       "  '1786356288',\n",
       "  '2245167018',\n",
       "  '2242862307',\n",
       "  '854350524',\n",
       "  '200589858',\n",
       "  '2702888010',\n",
       "  '1440137709',\n",
       "  '1948900320',\n",
       "  '1363642128',\n",
       "  '311636016',\n",
       "  '1675484991',\n",
       "  '703182762',\n",
       "  '1214251650',\n",
       "  '1901287332',\n",
       "  '1532129805',\n",
       "  '1532129805',\n",
       "  '432473184',\n",
       "  '2446979679',\n",
       "  '1149463179',\n",
       "  '2261472732',\n",
       "  '1427926203',\n",
       "  '1624371912',\n",
       "  '1136477988',\n",
       "  '2741428395',\n",
       "  '2537413785',\n",
       "  '2250304200',\n",
       "  '1052952084',\n",
       "  '988144722',\n",
       "  '1584943353',\n",
       "  '2225086308',\n",
       "  '2319128046',\n",
       "  '842823837',\n",
       "  '61920378',\n",
       "  '1210369140',\n",
       "  '2384868132',\n",
       "  '48988287',\n",
       "  '1640610837',\n",
       "  '2254272939',\n",
       "  '1193163363',\n",
       "  '1839741633',\n",
       "  '1839741633',\n",
       "  '997440237',\n",
       "  '732849417',\n",
       "  '2417963454',\n",
       "  '2249085627',\n",
       "  '692405856',\n",
       "  '2737201707',\n",
       "  '317604690',\n",
       "  '2628711936',\n",
       "  '2628711936',\n",
       "  '852117966',\n",
       "  '1694293083',\n",
       "  '1526199120',\n",
       "  '2404925253',\n",
       "  '1228964868',\n",
       "  '2376786348',\n",
       "  '2576213532',\n",
       "  '1622920932',\n",
       "  '97990857',\n",
       "  '485144433',\n",
       "  '1244158164',\n",
       "  '2561563476',\n",
       "  '1154741058',\n",
       "  '1260473904',\n",
       "  '1779690915',\n",
       "  '2273928732',\n",
       "  '1641985551',\n",
       "  '1585041750',\n",
       "  '1503200916',\n",
       "  '1177287750',\n",
       "  '454440564',\n",
       "  '2557396323',\n",
       "  '675697329',\n",
       "  '1063051515',\n",
       "  '2130690231',\n",
       "  '542764917',\n",
       "  '1038764115',\n",
       "  '1023295086',\n",
       "  '2397260637',\n",
       "  '1843316001',\n",
       "  '2606517558',\n",
       "  '2551718619',\n",
       "  '1004467302',\n",
       "  '586827450',\n",
       "  '2479316220',\n",
       "  '2479316220',\n",
       "  '2551718619',\n",
       "  '2441886363',\n",
       "  '442735020',\n",
       "  '2036881854',\n",
       "  '1385686278',\n",
       "  '886492062',\n",
       "  '2714375412',\n",
       "  '2041324452',\n",
       "  '794012148',\n",
       "  '794012148',\n",
       "  '202001463',\n",
       "  '949613094',\n",
       "  '2041200882',\n",
       "  '518856471',\n",
       "  '2143847529',\n",
       "  '1629158544',\n",
       "  '2143847529',\n",
       "  '1671825645',\n",
       "  '152472042',\n",
       "  '2085856929',\n",
       "  '880293249',\n",
       "  '950192811',\n",
       "  '1645130169',\n",
       "  '1139808474',\n",
       "  '1760942439',\n",
       "  '2505768390',\n",
       "  '1711975239',\n",
       "  '487471374',\n",
       "  '698530239',\n",
       "  '1302557931',\n",
       "  '1140788367',\n",
       "  '2621317158',\n",
       "  '82121094',\n",
       "  '2272318479',\n",
       "  '1832331312',\n",
       "  '1625534613',\n",
       "  '1681502571',\n",
       "  '2182398471',\n",
       "  '2065916835',\n",
       "  '2068868502',\n",
       "  '2641813461',\n",
       "  '704562300',\n",
       "  '470456343',\n",
       "  '1631510235',\n",
       "  '2119638915',\n",
       "  '2416298535',\n",
       "  '1392746544',\n",
       "  '1818804339',\n",
       "  '1137614616',\n",
       "  '1300392756',\n",
       "  '447684507',\n",
       "  '1969110342',\n",
       "  '2651357403',\n",
       "  '2002153131',\n",
       "  '2651590602',\n",
       "  '1566062919',\n",
       "  '704526624',\n",
       "  '2293784946',\n",
       "  '1263114675',\n",
       "  '1241368506',\n",
       "  '344210274',\n",
       "  '1923185646',\n",
       "  '2541657537',\n",
       "  '1581679278',\n",
       "  '1909324152',\n",
       "  '2132488296',\n",
       "  '832944042',\n",
       "  '918663327',\n",
       "  '1721969460',\n",
       "  '653031837',\n",
       "  '1114574427',\n",
       "  '498738024',\n",
       "  '114195924',\n",
       "  '447684507',\n",
       "  '306936486',\n",
       "  '2513700432',\n",
       "  '114195924',\n",
       "  '2480997807',\n",
       "  '2177946720',\n",
       "  '1380756870',\n",
       "  '809793846',\n",
       "  '1627226703',\n",
       "  '2004749568',\n",
       "  '1926902304',\n",
       "  '807808680',\n",
       "  '2654260083',\n",
       "  '1012636332',\n",
       "  '1983606174',\n",
       "  '2139347286',\n",
       "  '541906470',\n",
       "  '1092860190',\n",
       "  '1215541629',\n",
       "  '1190431107',\n",
       "  '2181066417',\n",
       "  '2368242009',\n",
       "  '1980997830',\n",
       "  '699159843',\n",
       "  '413524602',\n",
       "  '2305503333',\n",
       "  '1302985125',\n",
       "  '1154442528',\n",
       "  '920769399',\n",
       "  '2694491721',\n",
       "  '1972909368',\n",
       "  '1983953448',\n",
       "  '1579595292',\n",
       "  '172499517',\n",
       "  '759675132',\n",
       "  '1228239477',\n",
       "  '992291193',\n",
       "  '651317670',\n",
       "  '1937154771',\n",
       "  '1904097501',\n",
       "  '470065428',\n",
       "  '2187524799',\n",
       "  '1384886277',\n",
       "  '460727622',\n",
       "  '2244713733',\n",
       "  '796008888',\n",
       "  '1057615479',\n",
       "  '2622699279',\n",
       "  '914363658',\n",
       "  '1335062511',\n",
       "  '487910997',\n",
       "  '2523077631',\n",
       "  '1869517503',\n",
       "  '814614381',\n",
       "  '1826421570',\n",
       "  '21636729',\n",
       "  '81992070',\n",
       "  '2609450136',\n",
       "  '1217631231',\n",
       "  '1380587139',\n",
       "  '2331399231',\n",
       "  '660638466',\n",
       "  '2182614129',\n",
       "  '2132069058',\n",
       "  '154699659',\n",
       "  '1784914839',\n",
       "  '2560567095',\n",
       "  '2310261534',\n",
       "  '1119575799',\n",
       "  '1135669698',\n",
       "  '827372916',\n",
       "  '2538562365',\n",
       "  '2018841813',\n",
       "  '1718689545',\n",
       "  '656627184',\n",
       "  '2345575275',\n",
       "  '1845042588',\n",
       "  '2657877696',\n",
       "  '669257721',\n",
       "  '1877233923',\n",
       "  '755009712',\n",
       "  '1500372108',\n",
       "  '2606461515',\n",
       "  '1081784421',\n",
       "  '2745999045',\n",
       "  '1725157836',\n",
       "  '2688787206',\n",
       "  '2356574346',\n",
       "  '2290062546',\n",
       "  '1553439042',\n",
       "  '1506229389',\n",
       "  '1276911297',\n",
       "  '1368877617',\n",
       "  '1822032207',\n",
       "  '1698660873',\n",
       "  '1160162874',\n",
       "  '482505723',\n",
       "  '2622914352',\n",
       "  '1682030493',\n",
       "  '1247894415',\n",
       "  '1682030493',\n",
       "  '2151399690',\n",
       "  '692209782',\n",
       "  '89650008',\n",
       "  '1228228785',\n",
       "  '1305856458',\n",
       "  '2769052608',\n",
       "  '1525050765',\n",
       "  '2177518779',\n",
       "  '1604667627',\n",
       "  '410492925',\n",
       "  '2015261622',\n",
       "  '2774616237',\n",
       "  '433926558',\n",
       "  '2777020002',\n",
       "  '2428711749',\n",
       "  '977560839',\n",
       "  '495765360',\n",
       "  '2750432067',\n",
       "  '854185032',\n",
       "  '516053250',\n",
       "  '1312414866',\n",
       "  '1484551494',\n",
       "  '1145130381',\n",
       "  '630251946',\n",
       "  '805924638',\n",
       "  '1184592330',\n",
       "  '978448077',\n",
       "  '200737143',\n",
       "  '2671112277',\n",
       "  '1500372108',\n",
       "  '489028113',\n",
       "  '460615797',\n",
       "  '1697488965',\n",
       "  '2591297118',\n",
       "  '1557085185',\n",
       "  '1166464314',\n",
       "  '758811942',\n",
       "  '659584350',\n",
       "  '630403524',\n",
       "  '1565207397',\n",
       "  '77723964',\n",
       "  '200737143',\n",
       "  '214079544',\n",
       "  '2657877696',\n",
       "  '236205360',\n",
       "  '1909165185',\n",
       "  '2418353244',\n",
       "  '1035828801',\n",
       "  '829255707',\n",
       "  '690784119',\n",
       "  '1765172286',\n",
       "  '1790673732',\n",
       "  '476070642',\n",
       "  '1237467159',\n",
       "  '1749736287',\n",
       "  '1161516870',\n",
       "  '489865509',\n",
       "  '2219445108',\n",
       "  '1894016115',\n",
       "  '842556663',\n",
       "  '1910658870',\n",
       "  '2578549869',\n",
       "  '308047995',\n",
       "  '1285425162',\n",
       "  '2489338026',\n",
       "  '1765706481',\n",
       "  '753294654',\n",
       "  '1701485046',\n",
       "  '1542513600',\n",
       "  '2268980658',\n",
       "  '1799500581',\n",
       "  '477471321',\n",
       "  '736211826',\n",
       "  '936288162',\n",
       "  '2055364578',\n",
       "  '819514818',\n",
       "  '571797288',\n",
       "  '2431415682',\n",
       "  '1017620244',\n",
       "  '1858051269',\n",
       "  '173922372',\n",
       "  '953503065',\n",
       "  '2181790557',\n",
       "  '2576781441',\n",
       "  '2181066417',\n",
       "  '918465075',\n",
       "  '1454304420',\n",
       "  '2446724349',\n",
       "  '1393253631',\n",
       "  '2331399231',\n",
       "  '1244122272',\n",
       "  '1730032506',\n",
       "  '2036390526',\n",
       "  '58481424',\n",
       "  '425508885',\n",
       "  '2419793082',\n",
       "  '1295883072',\n",
       "  '44085150',\n",
       "  '824060097',\n",
       "  '2367037656',\n",
       "  '2157487875',\n",
       "  '1406681649',\n",
       "  '904376601',\n",
       "  '534398994',\n",
       "  '635665959',\n",
       "  '138801258',\n",
       "  '676459071',\n",
       "  '1742113152',\n",
       "  '101606562',\n",
       "  '2606461515',\n",
       "  '1137614616',\n",
       "  '1308467340',\n",
       "  '927578700',\n",
       "  '466445637',\n",
       "  '320304555',\n",
       "  '1722434805',\n",
       "  '658980576',\n",
       "  '2151399690',\n",
       "  '2651326182',\n",
       "  '1791974250',\n",
       "  '2479812714',\n",
       "  '1779665490',\n",
       "  '493745814',\n",
       "  '1927189368',\n",
       "  '700283781',\n",
       "  '985112595',\n",
       "  '2053696437',\n",
       "  '466371387',\n",
       "  '1832771988',\n",
       "  '442363032',\n",
       "  '2576648583',\n",
       "  '1020487203',\n",
       "  '1491897006',\n",
       "  '463524930',\n",
       "  '2249956953',\n",
       "  '2373368004',\n",
       "  '347251959',\n",
       "  '912138264',\n",
       "  '110661687',\n",
       "  '1960341201',\n",
       "  '1141151661',\n",
       "  '87385203',\n",
       "  '1452511251',\n",
       "  '909693954',\n",
       "  '933720327',\n",
       "  '919120347',\n",
       "  '964314225',\n",
       "  '898174791',\n",
       "  '188850096',\n",
       "  '1468388673',\n",
       "  '2104163271',\n",
       "  '989301978',\n",
       "  '463123908',\n",
       "  '1130728068',\n",
       "  '1158374844',\n",
       "  '1183755816',\n",
       "  '433926558',\n",
       "  '2728684458',\n",
       "  '1815229305',\n",
       "  '991395675',\n",
       "  '1765963089',\n",
       "  '509317884',\n",
       "  '944186535',\n",
       "  '639078849',\n",
       "  '1346736348',\n",
       "  '2327903586',\n",
       "  '2143222983',\n",
       "  '2591107542',\n",
       "  '793683072',\n",
       "  '1777256514',\n",
       "  '2413241316',\n",
       "  '1424662758',\n",
       "  '320325813',\n",
       "  '1939108428',\n",
       "  '649149471',\n",
       "  '2574317664',\n",
       "  '773070912',\n",
       "  '658980576',\n",
       "  '2695335399',\n",
       "  '566509635',\n",
       "  '2745999045',\n",
       "  '1843154181',\n",
       "  '1683862011',\n",
       "  '277119945',\n",
       "  '771756543',\n",
       "  '1380036690',\n",
       "  '2118925971',\n",
       "  '1581234804',\n",
       "  '2727098568',\n",
       "  '1313364933',\n",
       "  '552301272',\n",
       "  '2180664963',\n",
       "  '2669195592',\n",
       "  '1067703039',\n",
       "  '1266159771',\n",
       "  '2627848899',\n",
       "  '1834578360',\n",
       "  '1553983128',\n",
       "  '1577040435',\n",
       "  '1941027570',\n",
       "  '887828058',\n",
       "  '1358349687',\n",
       "  '636299586',\n",
       "  '1915758009',\n",
       "  '1192387905',\n",
       "  '809793846',\n",
       "  '2412591804',\n",
       "  '110661687',\n",
       "  '1846422999',\n",
       "  '1114057503',\n",
       "  '2200312647',\n",
       "  '1765963089',\n",
       "  '1158370101',\n",
       "  '1137313665',\n",
       "  '1386711459',\n",
       "  '478793844',\n",
       "  '2625491610',\n",
       "  '1470020391',\n",
       "  '2306019411',\n",
       "  '1905157197',\n",
       "  '1380756870',\n",
       "  '896145669',\n",
       "  ...],\n",
       " 'postId': ['5752863345',\n",
       "  '5488191835',\n",
       "  '1511838835',\n",
       "  '7741613935',\n",
       "  '7334551045',\n",
       "  '3837992835',\n",
       "  '9355285345',\n",
       "  '9112855735',\n",
       "  '9764723245',\n",
       "  '5516694045',\n",
       "  '3364298735',\n",
       "  '1709422935',\n",
       "  '7036452345',\n",
       "  '9668423245',\n",
       "  '7013260045',\n",
       "  '3148773835',\n",
       "  '1180872145',\n",
       "  '5080357045',\n",
       "  '5627681145',\n",
       "  '1086190245',\n",
       "  '7781339045',\n",
       "  '5573685245',\n",
       "  '3518784935',\n",
       "  '7684483835',\n",
       "  '9387534735',\n",
       "  '1538380145',\n",
       "  '7690120935',\n",
       "  '1003894245',\n",
       "  '7595135245',\n",
       "  '7696622445',\n",
       "  '5150366045',\n",
       "  '1908868835',\n",
       "  '1989785735',\n",
       "  '1259281045',\n",
       "  '1727221145',\n",
       "  '9652803735',\n",
       "  '7163913345',\n",
       "  '7505215835',\n",
       "  '7188245935',\n",
       "  '7035030045',\n",
       "  '1542364345',\n",
       "  '9422815245',\n",
       "  '7417756735',\n",
       "  '5301390045',\n",
       "  '1264172835',\n",
       "  '7431323345',\n",
       "  '7531793935',\n",
       "  '3146335835',\n",
       "  '5349534245',\n",
       "  '1280931245',\n",
       "  '5902479735',\n",
       "  '5616391935',\n",
       "  '9489282045',\n",
       "  '1683787245',\n",
       "  '9874689145',\n",
       "  '1190485145',\n",
       "  '5646623045',\n",
       "  '3529784345',\n",
       "  '5474223045',\n",
       "  '7185219245',\n",
       "  '7080443445',\n",
       "  '3474304245',\n",
       "  '9063484735',\n",
       "  '1642415245',\n",
       "  '7281423145',\n",
       "  '9107134045',\n",
       "  '9237914935',\n",
       "  '1326584345',\n",
       "  '5451745245',\n",
       "  '1870686245',\n",
       "  '3341880835',\n",
       "  '1921721245',\n",
       "  '7765291345',\n",
       "  '9129248935',\n",
       "  '7898594835',\n",
       "  '7345277045',\n",
       "  '9159952045',\n",
       "  '3577419935',\n",
       "  '5601608935',\n",
       "  '7988483245',\n",
       "  '7651122145',\n",
       "  '9856242735',\n",
       "  '7408243045',\n",
       "  '5573586935',\n",
       "  '7339867935',\n",
       "  '9838497045',\n",
       "  '5914604245',\n",
       "  '9926108145',\n",
       "  '5051513245',\n",
       "  '9537951245',\n",
       "  '5935130345',\n",
       "  '5055246835',\n",
       "  '3412622345',\n",
       "  '3411926345',\n",
       "  '7052197835',\n",
       "  '7684483835',\n",
       "  '3895686145',\n",
       "  '1896071245',\n",
       "  '1412739245',\n",
       "  '5392491245',\n",
       "  '7384031835',\n",
       "  '1466039145',\n",
       "  '3794036345',\n",
       "  '1981177935',\n",
       "  '3735433345',\n",
       "  '9457961935',\n",
       "  '5939495935',\n",
       "  '7275643245',\n",
       "  '1372678935',\n",
       "  '9308911345',\n",
       "  '9211334245',\n",
       "  '7406767245',\n",
       "  '1550262245',\n",
       "  '9862569935',\n",
       "  '3561596245',\n",
       "  '3672022445',\n",
       "  '5398818345',\n",
       "  '7506726345',\n",
       "  '7917005145',\n",
       "  '3865613045',\n",
       "  '7130823145',\n",
       "  '5090227835',\n",
       "  '7650280245',\n",
       "  '5781479245',\n",
       "  '3387856835',\n",
       "  '3284766245',\n",
       "  '7631261935',\n",
       "  '9434152245',\n",
       "  '5413531345',\n",
       "  '3064208245',\n",
       "  '3597200145',\n",
       "  '1374009735',\n",
       "  '1966436935',\n",
       "  '9319975045',\n",
       "  '9501334935',\n",
       "  '1985595935',\n",
       "  '1887677345',\n",
       "  '1483192735',\n",
       "  '9446992345',\n",
       "  '5263655245',\n",
       "  '9237914935',\n",
       "  '5323780835',\n",
       "  '7800693735',\n",
       "  '5964139245',\n",
       "  '9020573835',\n",
       "  '9886542835',\n",
       "  '7463609145',\n",
       "  '7652202835',\n",
       "  '1970736245',\n",
       "  '7248318935',\n",
       "  '5360861445',\n",
       "  '9674888935',\n",
       "  '7729565935',\n",
       "  '5870170345',\n",
       "  '9436324735',\n",
       "  '1678108345',\n",
       "  '1985595935',\n",
       "  '1280126735',\n",
       "  '7588687735',\n",
       "  '1821020145',\n",
       "  '5091514935',\n",
       "  '5457559835',\n",
       "  '1399586835',\n",
       "  '3151560935',\n",
       "  '7419333835',\n",
       "  '1017641345',\n",
       "  '9023569245',\n",
       "  '7809776835',\n",
       "  '7512603145',\n",
       "  '5896335735',\n",
       "  '5601608935',\n",
       "  '3711124345',\n",
       "  '7625206245',\n",
       "  '1092114935',\n",
       "  '9753470345',\n",
       "  '5742638735',\n",
       "  '1220094935',\n",
       "  '7108762835',\n",
       "  '1889851345',\n",
       "  '1692093935',\n",
       "  '9048621045',\n",
       "  '3402550045',\n",
       "  '7277625835',\n",
       "  '7298180835',\n",
       "  '3796035145',\n",
       "  '1936810245',\n",
       "  '5729367735',\n",
       "  '7543899145',\n",
       "  '9512365735',\n",
       "  '5542473045',\n",
       "  '7177029345',\n",
       "  '3095512245',\n",
       "  '5225055345',\n",
       "  '3171837935',\n",
       "  '9392736245',\n",
       "  '1549218935',\n",
       "  '1004174245',\n",
       "  '3867360835',\n",
       "  '7161604735',\n",
       "  '3584828345',\n",
       "  '1422253835',\n",
       "  '5603222245',\n",
       "  '1461151145',\n",
       "  '9977465935',\n",
       "  '3180743245',\n",
       "  '9710983045',\n",
       "  '5792962735',\n",
       "  '9107113935',\n",
       "  '1178671245',\n",
       "  '9036069835',\n",
       "  '1934903835',\n",
       "  '5604479045',\n",
       "  '1483747045',\n",
       "  '7787925735',\n",
       "  '1948084145',\n",
       "  '1879651345',\n",
       "  '1428575145',\n",
       "  '5552164245',\n",
       "  '9370190045',\n",
       "  '7243423735',\n",
       "  '1502592345',\n",
       "  '9517211935',\n",
       "  '5662021835',\n",
       "  '3401770835',\n",
       "  '5065077735',\n",
       "  '5767143045',\n",
       "  '3601660345',\n",
       "  '9702972245',\n",
       "  '1674812245',\n",
       "  '1034396935',\n",
       "  '7033008735',\n",
       "  '1833860145',\n",
       "  '9772650245',\n",
       "  '9172918935',\n",
       "  '1989785735',\n",
       "  '9519206735',\n",
       "  '9557872835',\n",
       "  '3971204245',\n",
       "  '1513111835',\n",
       "  '7640230245',\n",
       "  '7023331345',\n",
       "  '9691541835',\n",
       "  '3124791245',\n",
       "  '5668413935',\n",
       "  '3742054345',\n",
       "  '5430779835',\n",
       "  '5358378145',\n",
       "  '3756790935',\n",
       "  '7854341245',\n",
       "  '7545626245',\n",
       "  '3564049045',\n",
       "  '1669955045',\n",
       "  '5214268345',\n",
       "  '5888408245',\n",
       "  '7887322835',\n",
       "  '9316784935',\n",
       "  '7292945735',\n",
       "  '3354955145',\n",
       "  '7854341245',\n",
       "  '9310479245',\n",
       "  '9219952245',\n",
       "  '5943991345',\n",
       "  '1549277245',\n",
       "  '9477255835',\n",
       "  '5791343045',\n",
       "  '1200303935',\n",
       "  '5179374345',\n",
       "  '3175578245',\n",
       "  '7330109935',\n",
       "  '3366426245',\n",
       "  '1461339245',\n",
       "  '7700596735',\n",
       "  '5792962735',\n",
       "  '3867360835',\n",
       "  '7780318045',\n",
       "  '9931170835',\n",
       "  '1628638245',\n",
       "  '7700177735',\n",
       "  '5244084935',\n",
       "  '7884064145',\n",
       "  '3148532145',\n",
       "  '7031242935',\n",
       "  '3826878345',\n",
       "  '3277804345',\n",
       "  '9717534045',\n",
       "  '9317969145',\n",
       "  '9572422935',\n",
       "  '5726025245',\n",
       "  '7784776935',\n",
       "  '1710693835',\n",
       "  '3037741045',\n",
       "  '1762936735',\n",
       "  '1629453345',\n",
       "  '1571202935',\n",
       "  '1921869145',\n",
       "  '9083367735',\n",
       "  '7410523835',\n",
       "  '1442605245',\n",
       "  '9385659835',\n",
       "  '7752461935',\n",
       "  '9154285245',\n",
       "  '5809947735',\n",
       "  '1675204345',\n",
       "  '9831143345',\n",
       "  '9236746145',\n",
       "  '3858751345',\n",
       "  '9247151345',\n",
       "  '3029942145',\n",
       "  '7440664245',\n",
       "  '7448077935',\n",
       "  '1128552835',\n",
       "  '5870695245',\n",
       "  '1584627345',\n",
       "  '7237000835',\n",
       "  '9914178935',\n",
       "  '3414024045',\n",
       "  '7417811935',\n",
       "  '5514048835',\n",
       "  '5276875935',\n",
       "  '5350100345',\n",
       "  '9220516045',\n",
       "  '1037592345',\n",
       "  '9005212935',\n",
       "  '1543531835',\n",
       "  '9054871145',\n",
       "  '1757847735',\n",
       "  '5694394935',\n",
       "  '1558006045',\n",
       "  '3147083245',\n",
       "  '5332606345',\n",
       "  '5811923935',\n",
       "  '9158799045',\n",
       "  '9045191345',\n",
       "  '3794036345',\n",
       "  '1547723935',\n",
       "  '9443982245',\n",
       "  '3322906735',\n",
       "  '5887528835',\n",
       "  '3781906345',\n",
       "  '5866825835',\n",
       "  '1712053835',\n",
       "  '5337918045',\n",
       "  '9971603935',\n",
       "  '1180872145',\n",
       "  '1375496245',\n",
       "  '7861038245',\n",
       "  '7401748735',\n",
       "  '9004477245',\n",
       "  '3355990345',\n",
       "  '7906740935',\n",
       "  '9190293245',\n",
       "  '3053403245',\n",
       "  '5816503345',\n",
       "  '9600442045',\n",
       "  '9698539835',\n",
       "  '5438196145',\n",
       "  '7024975045',\n",
       "  '3626858045',\n",
       "  '5352297045',\n",
       "  '9615095245',\n",
       "  '7239859045',\n",
       "  '9015993735',\n",
       "  '1654102345',\n",
       "  '9506201935',\n",
       "  '3577419935',\n",
       "  '9735011345',\n",
       "  '9693468935',\n",
       "  '1842063935',\n",
       "  '1581011145',\n",
       "  '3519002345',\n",
       "  '1843904345',\n",
       "  '7002978835',\n",
       "  '5445649345',\n",
       "  '7774400935',\n",
       "  '7043414245',\n",
       "  '9594559935',\n",
       "  '5777717835',\n",
       "  '3913680935',\n",
       "  '1847214735',\n",
       "  '1653097045',\n",
       "  '1758223345',\n",
       "  '1525230345',\n",
       "  '3669441145',\n",
       "  '3524097935',\n",
       "  '3414024045',\n",
       "  '1628854935',\n",
       "  '1056324245',\n",
       "  '5014525145',\n",
       "  '7726677835',\n",
       "  '7389606145',\n",
       "  '7598970445',\n",
       "  '9413898935',\n",
       "  '3904571935',\n",
       "  '3651995245',\n",
       "  '1579296345',\n",
       "  '5864747735',\n",
       "  '1551925045',\n",
       "  '3764441935',\n",
       "  '9888113145',\n",
       "  '5615606835',\n",
       "  '3685117045',\n",
       "  '1868306735',\n",
       "  '7247295045',\n",
       "  '9456386245',\n",
       "  '5608088935',\n",
       "  '5955436345',\n",
       "  '7560672935',\n",
       "  '9437672935',\n",
       "  '1262927735',\n",
       "  '1701154145',\n",
       "  '1353976045',\n",
       "  '7666389045',\n",
       "  '9565994835',\n",
       "  '5351990345',\n",
       "  '5172766245',\n",
       "  '3730365045',\n",
       "  '5624027835',\n",
       "  '9829925045',\n",
       "  '1907412345',\n",
       "  '5350100345',\n",
       "  '3678409245',\n",
       "  '5365875245',\n",
       "  '9103335245',\n",
       "  '7539366045',\n",
       "  '9658002835',\n",
       "  '5553080445',\n",
       "  '1747595835',\n",
       "  '1392645345',\n",
       "  '3594474145',\n",
       "  '3285137145',\n",
       "  '1931779735',\n",
       "  '1273239835',\n",
       "  '1771927835',\n",
       "  '1768257735',\n",
       "  '9084704935',\n",
       "  '1762583045',\n",
       "  '7748888045',\n",
       "  '5515597345',\n",
       "  '5626267835',\n",
       "  '3059885735',\n",
       "  '3027403345',\n",
       "  '9561260835',\n",
       "  '9998252345',\n",
       "  '3097548735',\n",
       "  '9592664245',\n",
       "  '5775179245',\n",
       "  '1029838835',\n",
       "  '7491324345',\n",
       "  '3479323935',\n",
       "  '1865546735',\n",
       "  '7779182245',\n",
       "  '9183044245',\n",
       "  '9693468935',\n",
       "  '7474707045',\n",
       "  '7077327835',\n",
       "  '3953982145',\n",
       "  '9304559735',\n",
       "  '3162376935',\n",
       "  '1139074245',\n",
       "  '9676437735',\n",
       "  '5586473735',\n",
       "  '3301229835',\n",
       "  '5606753935',\n",
       "  '5749281445',\n",
       "  '7583858345',\n",
       "  '1001760345',\n",
       "  '5935749935',\n",
       "  '1786962835',\n",
       "  '9943577345',\n",
       "  '3255202345',\n",
       "  '7824631345',\n",
       "  '1587237835',\n",
       "  '5632557935',\n",
       "  '9570288935',\n",
       "  '5178375935',\n",
       "  '3171837935',\n",
       "  '7439038345',\n",
       "  '9530123145',\n",
       "  '9650665735',\n",
       "  '5098051045',\n",
       "  '1189156935',\n",
       "  '9500013835',\n",
       "  '3691067345',\n",
       "  '9674888935',\n",
       "  '5801853935',\n",
       "  '5261994345',\n",
       "  '5927854935',\n",
       "  '3438327245',\n",
       "  '5684929935',\n",
       "  '1372494735',\n",
       "  '3513463735',\n",
       "  '7822360045',\n",
       "  '7809776835',\n",
       "  '1668387145',\n",
       "  '5488683345',\n",
       "  '7880334145',\n",
       "  '7198751935',\n",
       "  '1347779835',\n",
       "  '7174657145',\n",
       "  '3004724045',\n",
       "  '5388290045',\n",
       "  '7893230145',\n",
       "  '3147542445',\n",
       "  '9455003345',\n",
       "  '7711261345',\n",
       "  '3459455145',\n",
       "  '5650169345',\n",
       "  '1995736345',\n",
       "  '9919244345',\n",
       "  '7125772145',\n",
       "  '5597386045',\n",
       "  '7852691835',\n",
       "  '1375137935',\n",
       "  '7236512345',\n",
       "  '3106265045',\n",
       "  '3073816735',\n",
       "  '5443485045',\n",
       "  '5044391145',\n",
       "  '9832650045',\n",
       "  '7356738735',\n",
       "  '5746672935',\n",
       "  '7375724045',\n",
       "  '5639952935',\n",
       "  '7560672935',\n",
       "  '5717198835',\n",
       "  '1079135345',\n",
       "  '3524370345',\n",
       "  '1981940245',\n",
       "  '9536998835',\n",
       "  '9154955045',\n",
       "  '5757589835',\n",
       "  '9879215245',\n",
       "  '3942465835',\n",
       "  '7432322245',\n",
       "  '9183369045',\n",
       "  '1638681145',\n",
       "  '5848191145',\n",
       "  '7445996145',\n",
       "  '5215489835',\n",
       "  '1898537245',\n",
       "  '7238908735',\n",
       "  '3961810445',\n",
       "  '3695331045',\n",
       "  '3834691045',\n",
       "  '7334597735',\n",
       "  '3488124145',\n",
       "  '1472911935',\n",
       "  '7698298835',\n",
       "  '1992951145',\n",
       "  '5350100345',\n",
       "  '5570589245',\n",
       "  '9989720345',\n",
       "  '9064027045',\n",
       "  '5098137245',\n",
       "  '9190293245',\n",
       "  '1933347045',\n",
       "  '5538648735',\n",
       "  '3805585345',\n",
       "  '7413080145',\n",
       "  '1243342345',\n",
       "  '5846285045',\n",
       "  '7698175245',\n",
       "  '3996804245',\n",
       "  '7393405345',\n",
       "  '5108813835',\n",
       "  '9499910345',\n",
       "  '7780133735',\n",
       "  '3828121835',\n",
       "  '7292506245',\n",
       "  '1237230345',\n",
       "  '1157274245',\n",
       "  '7269272245',\n",
       "  '9535857935',\n",
       "  '3567766835',\n",
       "  '1505578245',\n",
       "  '9240692345',\n",
       "  '1825901835',\n",
       "  '3132830045',\n",
       "  '7502535145',\n",
       "  '3474304245',\n",
       "  '7039671445',\n",
       "  '5378732245',\n",
       "  '5704873935',\n",
       "  '1378873045',\n",
       "  '1985595935',\n",
       "  '9504353345',\n",
       "  '3659705345',\n",
       "  '1103088245',\n",
       "  '7244766735',\n",
       "  '3485613145',\n",
       "  '5180707735',\n",
       "  '7700921445',\n",
       "  '1737426245',\n",
       "  '9668358245',\n",
       "  '3579983245',\n",
       "  '9789505835',\n",
       "  '1403808735',\n",
       "  '1764096045',\n",
       "  '7392708345',\n",
       "  '7743527835',\n",
       "  '7820651835',\n",
       "  '5349248735',\n",
       "  '9457961935',\n",
       "  '1360132835',\n",
       "  '7252221935',\n",
       "  '9904227935',\n",
       "  '9271268245',\n",
       "  '9997304245',\n",
       "  '1003894245',\n",
       "  '5058553145',\n",
       "  '7862749735',\n",
       "  '1260457935',\n",
       "  '1767752245',\n",
       "  '5135223145',\n",
       "  '1903294245',\n",
       "  '7988187935',\n",
       "  '3742054345',\n",
       "  '9282406345',\n",
       "  '9876021445',\n",
       "  '1295384045',\n",
       "  '7378357045',\n",
       "  '3577685735',\n",
       "  '7539366045',\n",
       "  '9557872835',\n",
       "  '9642523245',\n",
       "  '5012525145',\n",
       "  '5538648735',\n",
       "  '9909500345',\n",
       "  '3037555245',\n",
       "  '7985082735',\n",
       "  '7593834245',\n",
       "  '1602827735',\n",
       "  '3438258245',\n",
       "  '7931704345',\n",
       "  '3986223345',\n",
       "  '7869655245',\n",
       "  '1249920445',\n",
       "  '9953773835',\n",
       "  '1396996345',\n",
       "  '1568419145',\n",
       "  '5340507935',\n",
       "  '5345554835',\n",
       "  '9626843735',\n",
       "  '3782505835',\n",
       "  '7225563045',\n",
       "  '9149314735',\n",
       "  '7709027045',\n",
       "  '1290158345',\n",
       "  '1004416345',\n",
       "  '1281707045',\n",
       "  '3330203345',\n",
       "  '7458649935',\n",
       "  '5932964245',\n",
       "  '5474223045',\n",
       "  '1813105935',\n",
       "  '7023331345',\n",
       "  '3190689835',\n",
       "  '3455941835',\n",
       "  '9468525245',\n",
       "  '5731044735',\n",
       "  '3479323935',\n",
       "  '1975583145',\n",
       "  '5548843145',\n",
       "  '7590367345',\n",
       "  '5099838345',\n",
       "  '7836364245',\n",
       "  '5768780835',\n",
       "  '7491324345',\n",
       "  '3256094145',\n",
       "  '5365875245',\n",
       "  '5848334045',\n",
       "  '1366264245',\n",
       "  '9869328935',\n",
       "  '7093635735',\n",
       "  '1097320045',\n",
       "  '7653054245',\n",
       "  '7451470345',\n",
       "  '7936326935',\n",
       "  '3013681045',\n",
       "  '7160687145',\n",
       "  '9848289345',\n",
       "  '3025943735',\n",
       "  '9123692245',\n",
       "  '3579404735',\n",
       "  '9520614245',\n",
       "  '5102953445',\n",
       "  '1017154245',\n",
       "  '5573352245',\n",
       "  '5099522935',\n",
       "  '1417422045',\n",
       "  '3535927145',\n",
       "  '5223678935',\n",
       "  '1560226245',\n",
       "  '7065062735',\n",
       "  '7878162145',\n",
       "  '5674607835',\n",
       "  '9382442935',\n",
       "  '5966894245',\n",
       "  '1008142145',\n",
       "  '9110275145',\n",
       "  '5553345735',\n",
       "  '7992968735',\n",
       "  '5280613735',\n",
       "  '9114593735',\n",
       "  '9901380045',\n",
       "  '9289276735',\n",
       "  '3802135245',\n",
       "  '3990436245',\n",
       "  '3344164245',\n",
       "  '3743840145',\n",
       "  '5474233735',\n",
       "  '1282553345',\n",
       "  '5451151935',\n",
       "  '9355285345',\n",
       "  '3341880835',\n",
       "  '7854341245',\n",
       "  '5838823935',\n",
       "  '9745069935',\n",
       "  '7953558935',\n",
       "  '1660884045',\n",
       "  '1930687935',\n",
       "  '1017641345',\n",
       "  '7061232145',\n",
       "  '7237673045',\n",
       "  '1623648835',\n",
       "  '1898413145',\n",
       "  '5904981835',\n",
       "  '1937290445',\n",
       "  '3601660345',\n",
       "  '3890133045',\n",
       "  '5386575245',\n",
       "  '3744809935',\n",
       "  '1405266735',\n",
       "  '9050700345',\n",
       "  '9212127245',\n",
       "  '3216463045',\n",
       "  '1998073735',\n",
       "  '7921780935',\n",
       "  '9980536245',\n",
       "  '5667317145',\n",
       "  '1522325245',\n",
       "  '9326001045',\n",
       "  '7353441145',\n",
       "  '3613607145',\n",
       "  '7105239245',\n",
       "  '7037061445',\n",
       "  '3532452145',\n",
       "  '7970575835',\n",
       "  '1622680345',\n",
       "  '7061748045',\n",
       "  '9792190345',\n",
       "  '5650303935',\n",
       "  '3355231045',\n",
       "  '1132283345',\n",
       "  '1286290445',\n",
       "  '3270176735',\n",
       "  '3959484735',\n",
       "  '9571875935',\n",
       "  '3125231045',\n",
       "  '3154452345',\n",
       "  '5745843345',\n",
       "  '9878467045',\n",
       "  '7161604735',\n",
       "  '5625953045',\n",
       "  '9392276145',\n",
       "  '1185222145',\n",
       "  '9859872045',\n",
       "  '3849779735',\n",
       "  '7962981145',\n",
       "  '3176406735',\n",
       "  '3846594735',\n",
       "  '3339349245',\n",
       "  '7854341245',\n",
       "  '1923784345',\n",
       "  '5806810245',\n",
       "  '5677274935',\n",
       "  '3596359835',\n",
       "  '1201485835',\n",
       "  '5853658245',\n",
       "  '1538380145',\n",
       "  '5672093045',\n",
       "  '9679829935',\n",
       "  '9709674045',\n",
       "  '7282968045',\n",
       "  '3766038345',\n",
       "  '9500013835',\n",
       "  '7116207735',\n",
       "  '1399586835',\n",
       "  '9682588245',\n",
       "  '7076096345',\n",
       "  '9128219735',\n",
       "  '1112427145',\n",
       "  '1793276735',\n",
       "  '1867863145',\n",
       "  '5034930045',\n",
       "  '9596770045',\n",
       "  '9077343835',\n",
       "  '9439362835',\n",
       "  '3234028045',\n",
       "  '5614553935',\n",
       "  '3170961245',\n",
       "  '3722656835',\n",
       "  '7246605345',\n",
       "  '1760694735',\n",
       "  '9319236245',\n",
       "  '5792456245',\n",
       "  '9064495245',\n",
       "  '1910038935',\n",
       "  '5486080835',\n",
       "  '1595511935',\n",
       "  '3516590145',\n",
       "  '9402590445',\n",
       "  '7781339045',\n",
       "  '1971234835',\n",
       "  '3443965145',\n",
       "  '7515385735',\n",
       "  '7023331345',\n",
       "  '9094264245',\n",
       "  '9606079245',\n",
       "  '5678445145',\n",
       "  '5514473835',\n",
       "  '7456468245',\n",
       "  '9085117245',\n",
       "  '5392491245',\n",
       "  '7900240145',\n",
       "  '3302576045',\n",
       "  '5386575245',\n",
       "  '1563601935',\n",
       "  '7329550935',\n",
       "  '9237914935',\n",
       "  '5686380345',\n",
       "  '7854341245',\n",
       "  '7080960045',\n",
       "  '1399734935',\n",
       "  '3720168935',\n",
       "  '5350100345',\n",
       "  '1735003935',\n",
       "  '9818075735',\n",
       "  '5963347245',\n",
       "  '9817443045',\n",
       "  '3041484045',\n",
       "  '1958900045',\n",
       "  '1139074245',\n",
       "  '3019286835',\n",
       "  '7275643245',\n",
       "  '7135418145',\n",
       "  '1361567145',\n",
       "  '7554372345',\n",
       "  '7486683935',\n",
       "  '9745252245',\n",
       "  '9654304835',\n",
       "  '1735003935',\n",
       "  '3171837935',\n",
       "  '5353683145',\n",
       "  '1361567145',\n",
       "  '3669538735',\n",
       "  '5586935735',\n",
       "  '7396563045',\n",
       "  '3361359145',\n",
       "  '7764423735',\n",
       "  '7328760345',\n",
       "  '5438468935',\n",
       "  '9675024835',\n",
       "  '5678445145',\n",
       "  '5836177735',\n",
       "  '9182399935',\n",
       "  '5954638245',\n",
       "  '1537433345',\n",
       "  '1567994245',\n",
       "  '1636912735',\n",
       "  '9744799735',\n",
       "  '7795723145',\n",
       "  '1136764835',\n",
       "  '3865878345',\n",
       "  '9037616935',\n",
       "  '5931609145',\n",
       "  '5253986735',\n",
       "  '1501204245',\n",
       "  '1973804345',\n",
       "  '7511466935',\n",
       "  '7061232145',\n",
       "  '5346613045',\n",
       "  '7352519245',\n",
       "  '1723747145',\n",
       "  '1103104345',\n",
       "  '1874038345',\n",
       "  '7337601345',\n",
       "  '1048938245',\n",
       "  '1332981445',\n",
       "  '5236289835',\n",
       "  '3672547045',\n",
       "  '7648645835',\n",
       "  '9710896245',\n",
       "  '7532262935',\n",
       "  '7686107345',\n",
       "  '9514823735',\n",
       "  '5746672935',\n",
       "  '9854054045',\n",
       "  '1551411935',\n",
       "  '5071436045',\n",
       "  '1066128145',\n",
       "  '5459478735',\n",
       "  '7238753735',\n",
       "  '3263169045',\n",
       "  '3944183045',\n",
       "  '5573609145',\n",
       "  '7898080835',\n",
       "  '7254824835',\n",
       "  '1579202145',\n",
       "  '1568695045',\n",
       "  '7581221445',\n",
       "  '7756883045',\n",
       "  '9302592345',\n",
       "  '3355231045',\n",
       "  '9240692345',\n",
       "  '7611002345',\n",
       "  '3795058245',\n",
       "  '9061222345',\n",
       "  '7869884935',\n",
       "  '7417052835',\n",
       "  '5250090835',\n",
       "  '7909618935',\n",
       "  '7147215835',\n",
       "  '9554553145',\n",
       "  '9950933735',\n",
       "  '9289276735',\n",
       "  '3315085345',\n",
       "  '5691893145',\n",
       "  '1540193835',\n",
       "  '3037844245',\n",
       "  '1592899245',\n",
       "  '3707326145',\n",
       "  '5332523245',\n",
       "  '5767304345',\n",
       "  '7781339045',\n",
       "  '5365875245',\n",
       "  '9888473735',\n",
       "  '3866426345',\n",
       "  '7809776835',\n",
       "  '9499910345',\n",
       "  '9987576735',\n",
       "  '5080405245',\n",
       "  '5178707045',\n",
       "  '9593379045',\n",
       "  '9394662245',\n",
       "  '7063898935',\n",
       "  '3867360835',\n",
       "  '5735396145',\n",
       "  '1199576735',\n",
       "  '7714807735',\n",
       "  '5714438835',\n",
       "  '1208778735',\n",
       "  '5564088045',\n",
       "  '7150015245',\n",
       "  '9048581245',\n",
       "  '3188791045',\n",
       "  '5674607835',\n",
       "  '1819243735',\n",
       "  '5823586735',\n",
       "  '3730034245',\n",
       "  '3730918735',\n",
       "  '7698298835',\n",
       "  '7127726345',\n",
       "  '9922642345',\n",
       "  '9070526935',\n",
       "  '3723195245',\n",
       "  '9166283935',\n",
       "  '1659238345',\n",
       "  '1760694735',\n",
       "  '3317514045',\n",
       "  '5717223245',\n",
       "  '5021645935',\n",
       "  '5319510045',\n",
       "  '5214236145',\n",
       "  '3160875145',\n",
       "  '5412295045',\n",
       "  '9078915145',\n",
       "  '1697692735',\n",
       "  '1301193045',\n",
       "  '7328841445',\n",
       "  '7237984245',\n",
       "  '3867360835',\n",
       "  '5218851445',\n",
       "  '7625206245',\n",
       "  '7452721935',\n",
       "  '1837711345',\n",
       "  '3722656835',\n",
       "  '3690147245',\n",
       "  '1139074245',\n",
       "  '1417966935',\n",
       "  '7854341245',\n",
       "  '1250201345',\n",
       "  '9978423735',\n",
       "  '9488520245',\n",
       "  '3109073735',\n",
       "  '9203867735',\n",
       "  '1180872145',\n",
       "  '7186873735',\n",
       "  '1100393935',\n",
       "  '5358749045',\n",
       "  ...],\n",
       " 'groundtruth': [0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  ...],\n",
       " 'groundtruth2': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  ...],\n",
       " 'groundtruth3': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  ...],\n",
       " 'groundtruth4': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  ...],\n",
       " 'prediction': [1.1813784,\n",
       "  0.86494046,\n",
       "  4.3987856,\n",
       "  1.7248119,\n",
       "  5.8329315,\n",
       "  23.400826,\n",
       "  5.9874268,\n",
       "  4.7580233,\n",
       "  7.5977993,\n",
       "  8.732683,\n",
       "  3.7164547,\n",
       "  6.428587,\n",
       "  5.85925,\n",
       "  2.8409765,\n",
       "  5.0828443,\n",
       "  5.0051136,\n",
       "  6.032921,\n",
       "  10.662052,\n",
       "  3.4244256,\n",
       "  3.3289852,\n",
       "  5.8916216,\n",
       "  2.5014725,\n",
       "  0.0,\n",
       "  6.8046203,\n",
       "  5.7608232,\n",
       "  8.658623,\n",
       "  3.6074638,\n",
       "  2.1130924,\n",
       "  4.7619925,\n",
       "  1.496244,\n",
       "  6.255542,\n",
       "  2.939686,\n",
       "  5.0068846,\n",
       "  4.26447,\n",
       "  2.0984294,\n",
       "  0.5196995,\n",
       "  1.5285695,\n",
       "  10.4214325,\n",
       "  5.967894,\n",
       "  8.327164,\n",
       "  2.4725554,\n",
       "  2.6399984,\n",
       "  8.076414,\n",
       "  7.635444,\n",
       "  6.121567,\n",
       "  0.0,\n",
       "  5.509232,\n",
       "  0.08118713,\n",
       "  5.202309,\n",
       "  7.109111,\n",
       "  5.7886715,\n",
       "  3.5899925,\n",
       "  5.7508225,\n",
       "  2.2608535,\n",
       "  10.608505,\n",
       "  2.8027449,\n",
       "  4.2975764,\n",
       "  5.6838603,\n",
       "  7.3421183,\n",
       "  8.550835,\n",
       "  0.0,\n",
       "  3.4760318,\n",
       "  5.4376307,\n",
       "  3.6204162,\n",
       "  3.1484518,\n",
       "  8.392675,\n",
       "  4.0467234,\n",
       "  2.4772463,\n",
       "  1.0299519,\n",
       "  1.9641154,\n",
       "  3.3103602,\n",
       "  5.13658,\n",
       "  2.819932,\n",
       "  0.0,\n",
       "  3.1884084,\n",
       "  7.2520475,\n",
       "  11.20392,\n",
       "  4.979092,\n",
       "  8.076399,\n",
       "  7.21612,\n",
       "  3.096509,\n",
       "  6.207306,\n",
       "  31.997484,\n",
       "  0.0,\n",
       "  5.0953813,\n",
       "  0.735878,\n",
       "  11.625975,\n",
       "  1.6273382,\n",
       "  10.81036,\n",
       "  8.023794,\n",
       "  9.100943,\n",
       "  0.0,\n",
       "  2.299832,\n",
       "  5.4480796,\n",
       "  0.11272448,\n",
       "  5.4614573,\n",
       "  6.096422,\n",
       "  2.7010264,\n",
       "  5.5541797,\n",
       "  6.127383,\n",
       "  6.7139378,\n",
       "  2.1962335,\n",
       "  3.098963,\n",
       "  6.5406995,\n",
       "  1.8183157,\n",
       "  6.3494053,\n",
       "  6.7657866,\n",
       "  4.299041,\n",
       "  3.181697,\n",
       "  3.497767,\n",
       "  4.8719406,\n",
       "  5.647165,\n",
       "  8.601622,\n",
       "  1.5126648,\n",
       "  0.09069461,\n",
       "  0.97044086,\n",
       "  3.3832378,\n",
       "  0.0,\n",
       "  2.3184085,\n",
       "  6.9764957,\n",
       "  2.5437634,\n",
       "  5.9605556,\n",
       "  6.6187706,\n",
       "  0.12144858,\n",
       "  3.961864,\n",
       "  8.312866,\n",
       "  7.298098,\n",
       "  1.1391006,\n",
       "  5.7168136,\n",
       "  3.6238418,\n",
       "  2.6512063,\n",
       "  0.0,\n",
       "  1.6831208,\n",
       "  13.127453,\n",
       "  4.0480776,\n",
       "  6.7750974,\n",
       "  1.4034033,\n",
       "  3.1734037,\n",
       "  6.9659386,\n",
       "  6.5410247,\n",
       "  5.0335546,\n",
       "  5.6881094,\n",
       "  4.5576663,\n",
       "  0.0,\n",
       "  10.351511,\n",
       "  7.7473516,\n",
       "  6.3730164,\n",
       "  1.0252686,\n",
       "  6.3981543,\n",
       "  4.906264,\n",
       "  0.0,\n",
       "  8.935358,\n",
       "  10.095148,\n",
       "  1.3784386,\n",
       "  1.7329996,\n",
       "  4.6173983,\n",
       "  5.041763,\n",
       "  0.0,\n",
       "  8.099554,\n",
       "  7.0920196,\n",
       "  11.272238,\n",
       "  4.181881,\n",
       "  9.45332,\n",
       "  2.0317068,\n",
       "  3.4326565,\n",
       "  6.8958583,\n",
       "  1.3823764,\n",
       "  3.1331577,\n",
       "  5.9497085,\n",
       "  6.264443,\n",
       "  7.364191,\n",
       "  0.0,\n",
       "  4.160908,\n",
       "  7.336671,\n",
       "  4.0916586,\n",
       "  8.674141,\n",
       "  4.1326923,\n",
       "  8.186106,\n",
       "  0.0,\n",
       "  3.2625449,\n",
       "  8.950153,\n",
       "  1.7167909,\n",
       "  7.471797,\n",
       "  8.219858,\n",
       "  2.149044,\n",
       "  6.5367465,\n",
       "  7.0513797,\n",
       "  6.869503,\n",
       "  1.8183095,\n",
       "  5.26149,\n",
       "  2.7239313,\n",
       "  7.033743,\n",
       "  0.0,\n",
       "  7.5967007,\n",
       "  17.50715,\n",
       "  10.161146,\n",
       "  0.9687299,\n",
       "  13.132322,\n",
       "  14.560406,\n",
       "  6.314197,\n",
       "  0.0,\n",
       "  6.608678,\n",
       "  10.74474,\n",
       "  5.2895465,\n",
       "  7.1130576,\n",
       "  6.7199707,\n",
       "  7.4532905,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.3950129,\n",
       "  2.3911316,\n",
       "  4.8969016,\n",
       "  1.6286461,\n",
       "  5.369228,\n",
       "  3.2272,\n",
       "  1.1290058,\n",
       "  9.98736,\n",
       "  5.5649233,\n",
       "  6.542765,\n",
       "  2.0803924,\n",
       "  4.003676,\n",
       "  4.2075005,\n",
       "  2.374726,\n",
       "  9.114794,\n",
       "  4.704028,\n",
       "  0.0,\n",
       "  3.456514,\n",
       "  20.688435,\n",
       "  10.7020855,\n",
       "  11.724312,\n",
       "  6.20827,\n",
       "  2.0748587,\n",
       "  3.6212187,\n",
       "  1.1673734,\n",
       "  4.546493,\n",
       "  75.40338,\n",
       "  9.702021,\n",
       "  3.7523365,\n",
       "  11.684965,\n",
       "  0.9791688,\n",
       "  3.1523957,\n",
       "  3.7057195,\n",
       "  3.1418653,\n",
       "  5.2808714,\n",
       "  5.0048285,\n",
       "  4.2180767,\n",
       "  3.0864236,\n",
       "  2.3577368,\n",
       "  5.6109796,\n",
       "  2.7276583,\n",
       "  2.4155328,\n",
       "  3.1049178,\n",
       "  1.7089732,\n",
       "  5.883629,\n",
       "  10.259584,\n",
       "  6.669399,\n",
       "  5.0090804,\n",
       "  2.0329914,\n",
       "  6.321692,\n",
       "  6.7303905,\n",
       "  5.609644,\n",
       "  4.5319366,\n",
       "  4.1651354,\n",
       "  1.7609127,\n",
       "  4.3917074,\n",
       "  4.4938765,\n",
       "  9.089958,\n",
       "  0.35693508,\n",
       "  11.80195,\n",
       "  4.3947964,\n",
       "  6.9231763,\n",
       "  3.7389925,\n",
       "  0.0,\n",
       "  5.2838874,\n",
       "  7.4741626,\n",
       "  5.0009627,\n",
       "  0.0,\n",
       "  6.4060407,\n",
       "  2.6280107,\n",
       "  1.2392638,\n",
       "  2.4951866,\n",
       "  4.5747547,\n",
       "  7.245745,\n",
       "  1.3577797,\n",
       "  4.478285,\n",
       "  6.357202,\n",
       "  0.0,\n",
       "  3.8536313,\n",
       "  3.074375,\n",
       "  0.6372226,\n",
       "  6.998813,\n",
       "  3.39745,\n",
       "  2.5087583,\n",
       "  6.244677,\n",
       "  0.6001768,\n",
       "  1.3858504,\n",
       "  6.926838,\n",
       "  8.474979,\n",
       "  2.3290944,\n",
       "  1.848814,\n",
       "  8.098356,\n",
       "  0.0,\n",
       "  13.109274,\n",
       "  4.4908776,\n",
       "  7.0503373,\n",
       "  4.1143665,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.219593,\n",
       "  8.543821,\n",
       "  6.7429643,\n",
       "  1.648458,\n",
       "  1.4756961,\n",
       "  9.7498455,\n",
       "  6.076207,\n",
       "  10.882286,\n",
       "  10.543062,\n",
       "  1.9147675,\n",
       "  4.975123,\n",
       "  9.889685,\n",
       "  0.25500607,\n",
       "  2.2816105,\n",
       "  5.5840683,\n",
       "  6.0023456,\n",
       "  5.3234186,\n",
       "  5.4760394,\n",
       "  5.487418,\n",
       "  1.0486245,\n",
       "  3.955367,\n",
       "  3.5880594,\n",
       "  7.6854177,\n",
       "  6.4641356,\n",
       "  0.43386412,\n",
       "  7.421898,\n",
       "  5.995377,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.6620032,\n",
       "  0.0,\n",
       "  9.940866,\n",
       "  9.253607,\n",
       "  3.3264894,\n",
       "  6.1874237,\n",
       "  2.3467162,\n",
       "  7.016282,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.9970808,\n",
       "  2.728994,\n",
       "  3.6755657,\n",
       "  7.3416677,\n",
       "  7.088229,\n",
       "  2.0516708,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  5.53442,\n",
       "  10.469847,\n",
       "  11.561615,\n",
       "  2.320711,\n",
       "  0.025211096,\n",
       "  5.1020164,\n",
       "  11.438837,\n",
       "  9.221258,\n",
       "  4.540715,\n",
       "  9.814255,\n",
       "  4.9057765,\n",
       "  6.566946,\n",
       "  8.890535,\n",
       "  9.160852,\n",
       "  3.1209745,\n",
       "  5.3661275,\n",
       "  5.779701,\n",
       "  0.0,\n",
       "  7.896529,\n",
       "  0.7765177,\n",
       "  5.884902,\n",
       "  2.2367039,\n",
       "  6.2954445,\n",
       "  5.5621347,\n",
       "  10.399067,\n",
       "  7.184275,\n",
       "  1.3510283,\n",
       "  7.72745,\n",
       "  4.9428096,\n",
       "  7.437504,\n",
       "  11.683395,\n",
       "  0.0,\n",
       "  7.3200426,\n",
       "  6.6682224,\n",
       "  8.368206,\n",
       "  1.1091294,\n",
       "  7.510192,\n",
       "  0.0,\n",
       "  1.7795017,\n",
       "  0.45589197,\n",
       "  0.0,\n",
       "  2.0899851,\n",
       "  6.0722303,\n",
       "  5.018916,\n",
       "  8.493053,\n",
       "  3.2224963,\n",
       "  7.980243,\n",
       "  0.0,\n",
       "  7.0761423,\n",
       "  4.9287424,\n",
       "  0.7236724,\n",
       "  5.388189,\n",
       "  1.8303185,\n",
       "  2.3414624,\n",
       "  6.1667223,\n",
       "  5.677532,\n",
       "  7.29796,\n",
       "  5.100228,\n",
       "  3.1646576,\n",
       "  4.0137324,\n",
       "  3.107028,\n",
       "  12.034405,\n",
       "  4.669859,\n",
       "  1.7897925,\n",
       "  2.4517627,\n",
       "  3.4083176,\n",
       "  5.4598417,\n",
       "  4.679241,\n",
       "  10.174164,\n",
       "  1.9941384,\n",
       "  5.0201683,\n",
       "  7.7203755,\n",
       "  1.4248917,\n",
       "  4.0883636,\n",
       "  3.424785,\n",
       "  11.4604645,\n",
       "  5.3558264,\n",
       "  6.0500436,\n",
       "  1.3293872,\n",
       "  4.2731514,\n",
       "  4.8091135,\n",
       "  3.4919338,\n",
       "  13.640503,\n",
       "  1.4690949,\n",
       "  64.826256,\n",
       "  8.036461,\n",
       "  10.474905,\n",
       "  9.6863575,\n",
       "  0.0,\n",
       "  11.87874,\n",
       "  2.1258662,\n",
       "  8.898207,\n",
       "  15.09293,\n",
       "  7.072179,\n",
       "  5.3893356,\n",
       "  2.0570688,\n",
       "  2.5452595,\n",
       "  5.4225082,\n",
       "  7.385157,\n",
       "  4.7902274,\n",
       "  0.0,\n",
       "  8.342004,\n",
       "  3.803535,\n",
       "  0.32968962,\n",
       "  8.182266,\n",
       "  6.5839515,\n",
       "  4.4151297,\n",
       "  4.688077,\n",
       "  0.35158336,\n",
       "  0.0,\n",
       "  2.2611518,\n",
       "  3.4593377,\n",
       "  11.5903225,\n",
       "  6.4294853,\n",
       "  2.0168223,\n",
       "  8.979265,\n",
       "  3.053975,\n",
       "  1.1649997,\n",
       "  4.9784036,\n",
       "  6.488715,\n",
       "  8.088943,\n",
       "  2.8019946,\n",
       "  3.666287,\n",
       "  6.3999195,\n",
       "  0.6771277,\n",
       "  5.475345,\n",
       "  5.0545425,\n",
       "  5.9889083,\n",
       "  2.849969,\n",
       "  8.429877,\n",
       "  3.1065645,\n",
       "  5.731877,\n",
       "  0.25290477,\n",
       "  7.81217,\n",
       "  8.241095,\n",
       "  6.0513263,\n",
       "  4.639431,\n",
       "  3.0002563,\n",
       "  5.157763,\n",
       "  0.0,\n",
       "  8.26815,\n",
       "  1.5386491,\n",
       "  7.4151325,\n",
       "  6.0582476,\n",
       "  8.2869835,\n",
       "  0.0,\n",
       "  10.520115,\n",
       "  0.0,\n",
       "  3.4266994,\n",
       "  2.193275,\n",
       "  0.35228562,\n",
       "  1.3890264,\n",
       "  5.895832,\n",
       "  10.872482,\n",
       "  5.6875095,\n",
       "  0.2253322,\n",
       "  0.0,\n",
       "  0.81594604,\n",
       "  10.424873,\n",
       "  8.989944,\n",
       "  0.0,\n",
       "  7.2294183,\n",
       "  2.5245914,\n",
       "  1.9984194,\n",
       "  4.346441,\n",
       "  2.3168244,\n",
       "  1.018276,\n",
       "  1.8428607,\n",
       "  6.8442984,\n",
       "  1.25838,\n",
       "  0.0,\n",
       "  9.451363,\n",
       "  8.685249,\n",
       "  0.0,\n",
       "  3.8127375,\n",
       "  5.0226765,\n",
       "  1.8949121,\n",
       "  6.248957,\n",
       "  4.9177337,\n",
       "  3.9788043,\n",
       "  6.748016,\n",
       "  3.3067825,\n",
       "  3.077222,\n",
       "  0.0,\n",
       "  8.253594,\n",
       "  10.859987,\n",
       "  0.8979538,\n",
       "  6.770178,\n",
       "  11.137747,\n",
       "  8.402799,\n",
       "  3.9635625,\n",
       "  2.761168,\n",
       "  8.815739,\n",
       "  3.198266,\n",
       "  1.1609335,\n",
       "  2.3037794,\n",
       "  6.443368,\n",
       "  6.09489,\n",
       "  3.8127592,\n",
       "  9.2367115,\n",
       "  1.7189603,\n",
       "  4.881371,\n",
       "  2.4419315,\n",
       "  2.1123977,\n",
       "  5.1894245,\n",
       "  10.309809,\n",
       "  5.0105953,\n",
       "  6.1873636,\n",
       "  2.7807152,\n",
       "  10.211872,\n",
       "  4.0279818,\n",
       "  9.387886,\n",
       "  10.756535,\n",
       "  0.99934685,\n",
       "  4.464626,\n",
       "  1.3567297,\n",
       "  7.756509,\n",
       "  4.948953,\n",
       "  8.93586,\n",
       "  1.7720859,\n",
       "  2.1551156,\n",
       "  6.886971,\n",
       "  10.151367,\n",
       "  9.364429,\n",
       "  11.050398,\n",
       "  1.035614,\n",
       "  5.8332834,\n",
       "  7.3135204,\n",
       "  15.459362,\n",
       "  3.9307702,\n",
       "  1.7142991,\n",
       "  1.6912704,\n",
       "  0.0,\n",
       "  2.625181,\n",
       "  6.569628,\n",
       "  11.866522,\n",
       "  0.122193635,\n",
       "  7.798843,\n",
       "  6.2551255,\n",
       "  1.7521257,\n",
       "  14.544027,\n",
       "  6.196211,\n",
       "  7.289659,\n",
       "  4.272772,\n",
       "  5.9163136,\n",
       "  6.9392753,\n",
       "  1.8907828,\n",
       "  2.7577472,\n",
       "  4.2557664,\n",
       "  7.0404234,\n",
       "  5.323982,\n",
       "  1.8681036,\n",
       "  9.529692,\n",
       "  11.762741,\n",
       "  3.647243,\n",
       "  6.7433915,\n",
       "  7.084569,\n",
       "  0.0,\n",
       "  6.937959,\n",
       "  5.646354,\n",
       "  7.341635,\n",
       "  2.4924912,\n",
       "  0.0,\n",
       "  1.139759,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.6974819,\n",
       "  2.7824378,\n",
       "  0.56993043,\n",
       "  0.95596606,\n",
       "  8.479078,\n",
       "  7.8286114,\n",
       "  4.6732044,\n",
       "  0.0,\n",
       "  5.652829,\n",
       "  12.225431,\n",
       "  6.8616214,\n",
       "  4.4261074,\n",
       "  3.6430993,\n",
       "  5.8199196,\n",
       "  4.936921,\n",
       "  0.0,\n",
       "  9.235205,\n",
       "  0.99078727,\n",
       "  21.03128,\n",
       "  5.6170945,\n",
       "  1.9156228,\n",
       "  33.13752,\n",
       "  4.2473187,\n",
       "  8.459651,\n",
       "  7.0497656,\n",
       "  3.8541725,\n",
       "  0.0,\n",
       "  3.2298734,\n",
       "  6.2431493,\n",
       "  0.0,\n",
       "  5.6239305,\n",
       "  4.6824064,\n",
       "  3.8858576,\n",
       "  0.0,\n",
       "  6.8580585,\n",
       "  1.9704292,\n",
       "  4.06522,\n",
       "  7.069273,\n",
       "  5.1361756,\n",
       "  6.842999,\n",
       "  8.154497,\n",
       "  1.7292622,\n",
       "  4.775475,\n",
       "  0.24093735,\n",
       "  1.2604983,\n",
       "  7.655659,\n",
       "  11.9039345,\n",
       "  3.7657816,\n",
       "  2.8560193,\n",
       "  7.730834,\n",
       "  12.6806965,\n",
       "  0.10275298,\n",
       "  5.3207407,\n",
       "  0.0,\n",
       "  2.3403049,\n",
       "  0.0,\n",
       "  6.1666336,\n",
       "  1.6270196,\n",
       "  5.611237,\n",
       "  3.373592,\n",
       "  4.441225,\n",
       "  5.7280664,\n",
       "  3.0002027,\n",
       "  6.5782294,\n",
       "  1.1331666,\n",
       "  18.080513,\n",
       "  28.781582,\n",
       "  4.3568487,\n",
       "  5.0320315,\n",
       "  3.4192376,\n",
       "  8.0972805,\n",
       "  3.2454267,\n",
       "  7.015469,\n",
       "  7.0100026,\n",
       "  7.1986747,\n",
       "  10.708677,\n",
       "  0.0,\n",
       "  9.633724,\n",
       "  9.3473015,\n",
       "  4.4275994,\n",
       "  7.5069327,\n",
       "  4.6947002,\n",
       "  2.969949,\n",
       "  2.7784655,\n",
       "  3.486699,\n",
       "  2.919845,\n",
       "  5.253512,\n",
       "  6.240865,\n",
       "  3.1045077,\n",
       "  3.8425236,\n",
       "  8.39311,\n",
       "  4.3804965,\n",
       "  1.3913361,\n",
       "  12.276388,\n",
       "  4.495407,\n",
       "  8.221616,\n",
       "  6.0650983,\n",
       "  8.960705,\n",
       "  7.644583,\n",
       "  0.98976326,\n",
       "  3.5491748,\n",
       "  12.674091,\n",
       "  4.6120586,\n",
       "  3.4789805,\n",
       "  1.6712346,\n",
       "  4.6606874,\n",
       "  0.0,\n",
       "  2.7221353,\n",
       "  6.598269,\n",
       "  1.3308673,\n",
       "  2.076461,\n",
       "  6.108405,\n",
       "  1.1039913,\n",
       "  4.4905534,\n",
       "  2.4383278,\n",
       "  1.9737608,\n",
       "  4.500305,\n",
       "  3.4695697,\n",
       "  0.0,\n",
       "  3.8851805,\n",
       "  3.3670394,\n",
       "  3.4635744,\n",
       "  8.135588,\n",
       "  2.592227,\n",
       "  1.0498898,\n",
       "  10.523022,\n",
       "  11.147345,\n",
       "  0.0,\n",
       "  3.439938,\n",
       "  3.429141,\n",
       "  14.232159,\n",
       "  2.4401355,\n",
       "  2.5230923,\n",
       "  0.0,\n",
       "  5.8966284,\n",
       "  1.9033267,\n",
       "  2.4480133,\n",
       "  0.0,\n",
       "  2.6879969,\n",
       "  0.0,\n",
       "  6.667008,\n",
       "  10.352051,\n",
       "  1.7315259,\n",
       "  3.8815956,\n",
       "  5.295224,\n",
       "  4.2066846,\n",
       "  4.105098,\n",
       "  6.0378685,\n",
       "  3.6112843,\n",
       "  6.7535987,\n",
       "  10.675367,\n",
       "  6.5740304,\n",
       "  2.3087125,\n",
       "  0.5023368,\n",
       "  7.625501,\n",
       "  6.6912475,\n",
       "  9.194248,\n",
       "  0.0,\n",
       "  6.1243806,\n",
       "  4.76311,\n",
       "  0.9541453,\n",
       "  5.682947,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.8847678,\n",
       "  5.3599257,\n",
       "  3.8194594,\n",
       "  9.491642,\n",
       "  6.601443,\n",
       "  2.737608,\n",
       "  0.98610467,\n",
       "  3.297752,\n",
       "  7.004803,\n",
       "  6.330055,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  5.445929,\n",
       "  2.0250463,\n",
       "  7.2264833,\n",
       "  3.485404,\n",
       "  7.760036,\n",
       "  8.944822,\n",
       "  1.5428855,\n",
       "  2.484221,\n",
       "  5.303929,\n",
       "  0.0,\n",
       "  0.9511278,\n",
       "  2.1655498,\n",
       "  1.9342266,\n",
       "  3.0734584,\n",
       "  0.0,\n",
       "  5.101533,\n",
       "  5.64209,\n",
       "  6.926452,\n",
       "  6.755536,\n",
       "  7.5162334,\n",
       "  3.4335494,\n",
       "  6.5279217,\n",
       "  5.356725,\n",
       "  5.694714,\n",
       "  4.037962,\n",
       "  0.0,\n",
       "  7.8856583,\n",
       "  2.1676743,\n",
       "  6.273634,\n",
       "  6.6988482,\n",
       "  11.216856,\n",
       "  5.8060737,\n",
       "  5.1485176,\n",
       "  10.65415,\n",
       "  5.2646866,\n",
       "  6.768205,\n",
       "  0.0,\n",
       "  10.643414,\n",
       "  2.4614232,\n",
       "  10.113665,\n",
       "  4.4722877,\n",
       "  6.0784106,\n",
       "  1.2960219,\n",
       "  4.724659,\n",
       "  0.17490566,\n",
       "  4.7090487,\n",
       "  2.2987456,\n",
       "  3.4786854,\n",
       "  3.6290078,\n",
       "  7.4415975,\n",
       "  7.7579155,\n",
       "  1.9379761,\n",
       "  10.605183,\n",
       "  5.420032,\n",
       "  3.6052847,\n",
       "  6.530743,\n",
       "  4.6750116,\n",
       "  6.098059,\n",
       "  2.9086373,\n",
       "  12.174631,\n",
       "  2.032094,\n",
       "  5.2028146,\n",
       "  3.0470884,\n",
       "  0.0,\n",
       "  7.651279,\n",
       "  8.1845875,\n",
       "  5.799778,\n",
       "  1.8078022,\n",
       "  4.275815,\n",
       "  0.0,\n",
       "  5.6514235,\n",
       "  1.69081,\n",
       "  6.3312554,\n",
       "  0.0,\n",
       "  1.936624,\n",
       "  2.6415768,\n",
       "  13.405195,\n",
       "  1.6567278,\n",
       "  7.0395923,\n",
       "  3.7672098,\n",
       "  6.64165,\n",
       "  8.146734,\n",
       "  3.1350005,\n",
       "  8.533064,\n",
       "  7.150634,\n",
       "  3.178509,\n",
       "  3.6458917,\n",
       "  5.091979,\n",
       "  1.1774194,\n",
       "  4.7634273,\n",
       "  0.8365056,\n",
       "  2.0537777,\n",
       "  5.105074,\n",
       "  3.2604406,\n",
       "  5.976681,\n",
       "  5.251618,\n",
       "  14.258699,\n",
       "  0.0,\n",
       "  4.233728,\n",
       "  1.9686823,\n",
       "  5.130202,\n",
       "  6.493783,\n",
       "  4.635475,\n",
       "  5.0165725,\n",
       "  3.2726345,\n",
       "  5.784105,\n",
       "  5.8196373,\n",
       "  0.0,\n",
       "  5.7536902,\n",
       "  2.3148918,\n",
       "  0.0,\n",
       "  4.506777,\n",
       "  7.13342,\n",
       "  8.017959,\n",
       "  7.071086,\n",
       "  0.7487965,\n",
       "  7.1951804,\n",
       "  2.175594,\n",
       "  0.0,\n",
       "  1.3165042,\n",
       "  4.8901315,\n",
       "  7.762318,\n",
       "  4.572652,\n",
       "  7.5495963,\n",
       "  3.741189,\n",
       "  8.325831,\n",
       "  1.8668435,\n",
       "  6.442914,\n",
       "  4.3657417,\n",
       "  5.972705,\n",
       "  1.6708907,\n",
       "  7.9717107,\n",
       "  0.5000729,\n",
       "  8.0102825,\n",
       "  5.628508,\n",
       "  6.3199143,\n",
       "  6.3014164,\n",
       "  4.3031917,\n",
       "  6.4772983,\n",
       "  2.2908902,\n",
       "  0.0,\n",
       "  6.237626,\n",
       "  5.783572,\n",
       "  9.347254,\n",
       "  8.370972,\n",
       "  6.2237873,\n",
       "  7.399818,\n",
       "  0.98594934,\n",
       "  6.2930145,\n",
       "  6.055506,\n",
       "  3.8560133,\n",
       "  9.944799,\n",
       "  2.9912634,\n",
       "  11.148615,\n",
       "  10.93029,\n",
       "  5.13172,\n",
       "  8.393465,\n",
       "  0.9193865,\n",
       "  7.6283584,\n",
       "  4.128577,\n",
       "  3.9998167,\n",
       "  7.369434,\n",
       "  12.8594055,\n",
       "  6.7890472,\n",
       "  6.6331935,\n",
       "  1.7598336,\n",
       "  0.40309668,\n",
       "  6.524188,\n",
       "  2.629732,\n",
       "  8.008305,\n",
       "  6.5383267,\n",
       "  0.0,\n",
       "  3.0183268,\n",
       "  3.9358423,\n",
       "  12.082199,\n",
       "  0.0,\n",
       "  3.1159055,\n",
       "  5.0238442,\n",
       "  7.7218537,\n",
       "  7.314775,\n",
       "  2.3358388,\n",
       "  3.6882305,\n",
       "  0.0,\n",
       "  4.1316366,\n",
       "  6.2040343,\n",
       "  6.087859,\n",
       "  6.473148,\n",
       "  10.060513,\n",
       "  1.2271564,\n",
       "  5.3678346,\n",
       "  0.0,\n",
       "  5.1099906,\n",
       "  0.0,\n",
       "  7.2236905,\n",
       "  0.0031583905,\n",
       "  5.8904734,\n",
       "  4.02915,\n",
       "  2.669376,\n",
       "  6.111804,\n",
       "  7.9979897,\n",
       "  9.404409,\n",
       "  6.479994,\n",
       "  4.789021,\n",
       "  ...],\n",
       " 'production_model_prediction_unified': [0.6075,\n",
       "  10.6095,\n",
       "  0.47825,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  32.85075,\n",
       "  7.00325,\n",
       "  0.422,\n",
       "  10.947,\n",
       "  0.21375,\n",
       "  2.48625,\n",
       "  4.89375,\n",
       "  1.4175,\n",
       "  2.55925,\n",
       "  1.33875,\n",
       "  9.5745,\n",
       "  0.0,\n",
       "  9.878,\n",
       "  10.77825,\n",
       "  3.78,\n",
       "  0.0,\n",
       "  2.925,\n",
       "  0.0,\n",
       "  1.097,\n",
       "  1.98,\n",
       "  14.575,\n",
       "  100.358,\n",
       "  4.725,\n",
       "  6.075,\n",
       "  0.658,\n",
       "  0.86075,\n",
       "  0.0,\n",
       "  0.75925,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  11.4755,\n",
       "  10.452,\n",
       "  10.69375,\n",
       "  0.75925,\n",
       "  1.09675,\n",
       "  1.33875,\n",
       "  10.255,\n",
       "  0.8155,\n",
       "  11.04825,\n",
       "  0.23625,\n",
       "  10.8625,\n",
       "  2.86875,\n",
       "  34.43125,\n",
       "  16.2625,\n",
       "  1.097,\n",
       "  0.6075,\n",
       "  3.25125,\n",
       "  13.60325,\n",
       "  9.76,\n",
       "  4.05,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  7.18875,\n",
       "  2.97575,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.57125,\n",
       "  0.0,\n",
       "  9.2425,\n",
       "  1.4345,\n",
       "  3.9655,\n",
       "  1.02375,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6695,\n",
       "  19.0075,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  7.245,\n",
       "  0.80425,\n",
       "  11.36875,\n",
       "  1.31625,\n",
       "  12.26875,\n",
       "  10.10325,\n",
       "  3.0375,\n",
       "  11.29,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  9.59125,\n",
       "  0.0,\n",
       "  2.43,\n",
       "  8.022,\n",
       "  16.75925,\n",
       "  4.01625,\n",
       "  2.582,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.25125,\n",
       "  0.0,\n",
       "  10.77825,\n",
       "  1.18125,\n",
       "  3.54375,\n",
       "  11.04825,\n",
       "  1.215,\n",
       "  0.0,\n",
       "  0.675,\n",
       "  15.8405,\n",
       "  16.5325,\n",
       "  0.64125,\n",
       "  11.28425,\n",
       "  0.9,\n",
       "  0.74825,\n",
       "  2.52,\n",
       "  2.03075,\n",
       "  0.81,\n",
       "  1.575,\n",
       "  14.26575,\n",
       "  6.84,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  10.01875,\n",
       "  10.83425,\n",
       "  11.2,\n",
       "  16.54,\n",
       "  2.1095,\n",
       "  0.43875,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  11.875,\n",
       "  1.72125,\n",
       "  2.53125,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  11.03125,\n",
       "  1.02375,\n",
       "  1.0125,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  10.57,\n",
       "  0.0,\n",
       "  3.9655,\n",
       "  11.2,\n",
       "  10.55875,\n",
       "  0.0,\n",
       "  1.6255,\n",
       "  10.10325,\n",
       "  1.32175,\n",
       "  0.0,\n",
       "  11.875,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.35,\n",
       "  11.9595,\n",
       "  2.53125,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.75925,\n",
       "  0.0,\n",
       "  7.787,\n",
       "  5.11875,\n",
       "  10.30575,\n",
       "  11.03125,\n",
       "  1.4345,\n",
       "  2.1095,\n",
       "  0.0,\n",
       "  10.80625,\n",
       "  0.0,\n",
       "  1.2655,\n",
       "  0.0,\n",
       "  9.79375,\n",
       "  10.64325,\n",
       "  0.0,\n",
       "  0.675,\n",
       "  29.6725,\n",
       "  12.2175,\n",
       "  1.40625,\n",
       "  10.8625,\n",
       "  0.50625,\n",
       "  2.835,\n",
       "  0.0,\n",
       "  9.5745,\n",
       "  2.27825,\n",
       "  4.06125,\n",
       "  5.90625,\n",
       "  5.8725,\n",
       "  21.6625,\n",
       "  0.0,\n",
       "  5.5125,\n",
       "  0.4725,\n",
       "  5.54625,\n",
       "  1.77175,\n",
       "  39.01,\n",
       "  0.0,\n",
       "  21.072,\n",
       "  0.675,\n",
       "  1.38375,\n",
       "  5.3155,\n",
       "  44.02175,\n",
       "  31.5175,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.39075,\n",
       "  1.0125,\n",
       "  0.0,\n",
       "  2.6325,\n",
       "  2.1995,\n",
       "  0.315,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.54375,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.34,\n",
       "  2.295,\n",
       "  0.0,\n",
       "  0.99,\n",
       "  11.065,\n",
       "  11.0,\n",
       "  0.928,\n",
       "  3.375,\n",
       "  0.0,\n",
       "  3.54375,\n",
       "  0.3375,\n",
       "  0.99,\n",
       "  0.0,\n",
       "  10.947,\n",
       "  25.4425,\n",
       "  9.282,\n",
       "  2.025,\n",
       "  0.0,\n",
       "  1.2345,\n",
       "  0.4275,\n",
       "  1.51875,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  17.3425,\n",
       "  0.422,\n",
       "  11.5995,\n",
       "  0.0,\n",
       "  1.4625,\n",
       "  2.3625,\n",
       "  0.0,\n",
       "  10.77825,\n",
       "  1.53,\n",
       "  9.85,\n",
       "  0.0,\n",
       "  10.9245,\n",
       "  1.4175,\n",
       "  1.35,\n",
       "  16.57425,\n",
       "  3.7125,\n",
       "  2.90825,\n",
       "  10.6095,\n",
       "  0.675,\n",
       "  0.6695,\n",
       "  10.69375,\n",
       "  3.797,\n",
       "  1.4175,\n",
       "  2.27825,\n",
       "  11.875,\n",
       "  14.6925,\n",
       "  33.728,\n",
       "  1.0125,\n",
       "  3.54375,\n",
       "  1.51875,\n",
       "  10.947,\n",
       "  0.0,\n",
       "  19.71075,\n",
       "  10.6095,\n",
       "  10.6095,\n",
       "  1.08,\n",
       "  0.0,\n",
       "  0.675,\n",
       "  10.77825,\n",
       "  1.85625,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.30375,\n",
       "  4.19075,\n",
       "  6.84,\n",
       "  0.6525,\n",
       "  2.1995,\n",
       "  0.0,\n",
       "  4.80925,\n",
       "  9.175,\n",
       "  0.0,\n",
       "  0.495,\n",
       "  0.39375,\n",
       "  0.3095,\n",
       "  0.8325,\n",
       "  10.83425,\n",
       "  3.06,\n",
       "  0.945,\n",
       "  0.0,\n",
       "  0.6695,\n",
       "  13.4345,\n",
       "  3.74625,\n",
       "  0.0,\n",
       "  5.85,\n",
       "  21.0375,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.25875,\n",
       "  10.947,\n",
       "  0.86625,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.55125,\n",
       "  10.0975,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  11.0,\n",
       "  0.0,\n",
       "  13.68,\n",
       "  5.90625,\n",
       "  19.89075,\n",
       "  11.605,\n",
       "  0.0,\n",
       "  2.88,\n",
       "  0.91125,\n",
       "  1.3895,\n",
       "  22.5905,\n",
       "  0.74825,\n",
       "  1.89,\n",
       "  7.0875,\n",
       "  0.0,\n",
       "  1.0125,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  12.65125,\n",
       "  0.6695,\n",
       "  0.0,\n",
       "  11.2,\n",
       "  0.84375,\n",
       "  0.74825,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  11.2,\n",
       "  1.24325,\n",
       "  10.10325,\n",
       "  3.0375,\n",
       "  1.18125,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.1375,\n",
       "  1.0125,\n",
       "  20.44675,\n",
       "  10.947,\n",
       "  10.69375,\n",
       "  1.65375,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.928,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  11.34,\n",
       "  0.5345,\n",
       "  0.422,\n",
       "  27.82175,\n",
       "  0.0,\n",
       "  1.2655,\n",
       "  1.8225,\n",
       "  0.0,\n",
       "  6.32825,\n",
       "  3.63375,\n",
       "  2.7055,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.15,\n",
       "  0.0,\n",
       "  3.45925,\n",
       "  4.472,\n",
       "  4.05,\n",
       "  1.82825,\n",
       "  1.18125,\n",
       "  0.0,\n",
       "  1.51875,\n",
       "  10.255,\n",
       "  0.54,\n",
       "  12.347,\n",
       "  21.747,\n",
       "  20.903,\n",
       "  10.947,\n",
       "  0.0,\n",
       "  11.80375,\n",
       "  0.0,\n",
       "  10.73875,\n",
       "  0.0,\n",
       "  9.50125,\n",
       "  0.0,\n",
       "  0.7425,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.51875,\n",
       "  9.70375,\n",
       "  0.0,\n",
       "  10.3,\n",
       "  10.27175,\n",
       "  2.03075,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.055,\n",
       "  0.0,\n",
       "  9.76575,\n",
       "  1.49625,\n",
       "  1.4175,\n",
       "  12.938,\n",
       "  4.5,\n",
       "  20.903,\n",
       "  0.0,\n",
       "  4.48875,\n",
       "  3.4425,\n",
       "  11.16575,\n",
       "  12.865,\n",
       "  1.35,\n",
       "  0.0,\n",
       "  6.01,\n",
       "  0.86625,\n",
       "  10.255,\n",
       "  3.45925,\n",
       "  0.43875,\n",
       "  1.1025,\n",
       "  12.79375,\n",
       "  10.69375,\n",
       "  0.0,\n",
       "  23.0825,\n",
       "  5.5125,\n",
       "  13.18575,\n",
       "  2.75625,\n",
       "  100.89625,\n",
       "  0.0,\n",
       "  4.472,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.9825,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  13.09,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  22.50625,\n",
       "  0.0,\n",
       "  10.1875,\n",
       "  0.0,\n",
       "  11.982,\n",
       "  10.01875,\n",
       "  9.625,\n",
       "  0.0,\n",
       "  0.50625,\n",
       "  10.33375,\n",
       "  0.253,\n",
       "  1.215,\n",
       "  10.01875,\n",
       "  2.99825,\n",
       "  1.3895,\n",
       "  10.83425,\n",
       "  9.85,\n",
       "  0.0,\n",
       "  19.3,\n",
       "  2.1375,\n",
       "  0.0,\n",
       "  0.45,\n",
       "  9.5125,\n",
       "  0.0,\n",
       "  8.9345,\n",
       "  0.0,\n",
       "  10.77825,\n",
       "  0.0,\n",
       "  0.86625,\n",
       "  9.58,\n",
       "  12.17825,\n",
       "  21.48425,\n",
       "  0.0,\n",
       "  0.54,\n",
       "  0.928,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  10.6095,\n",
       "  10.6095,\n",
       "  10.947,\n",
       "  1.4345,\n",
       "  12.36875,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  4.86,\n",
       "  13.93375,\n",
       "  19.80625,\n",
       "  19.80625,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  6.37875,\n",
       "  29.29,\n",
       "  5.74875,\n",
       "  2.88575,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.16875,\n",
       "  2.55925,\n",
       "  9.76575,\n",
       "  10.11375,\n",
       "  2.1095,\n",
       "  1.4345,\n",
       "  0.0,\n",
       "  15.57,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  27.90625,\n",
       "  16.51575,\n",
       "  0.0,\n",
       "  15.92125,\n",
       "  3.54375,\n",
       "  3.36375,\n",
       "  0.32075,\n",
       "  1.5355,\n",
       "  0.0,\n",
       "  0.7425,\n",
       "  14.4905,\n",
       "  2.7,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.7595,\n",
       "  0.0,\n",
       "  0.945,\n",
       "  7.34075,\n",
       "  1.2655,\n",
       "  7.32375,\n",
       "  0.0,\n",
       "  1.4625,\n",
       "  4.8995,\n",
       "  0.84375,\n",
       "  6.5025,\n",
       "  0.0,\n",
       "  0.928,\n",
       "  0.0,\n",
       "  10.51325,\n",
       "  41.98575,\n",
       "  11.70625,\n",
       "  10.77825,\n",
       "  0.0,\n",
       "  11.155,\n",
       "  11.7625,\n",
       "  0.0,\n",
       "  3.6,\n",
       "  2.75625,\n",
       "  0.0,\n",
       "  10.69375,\n",
       "  0.945,\n",
       "  12.04375,\n",
       "  0.152,\n",
       "  11.79075,\n",
       "  0.63,\n",
       "  3.63375,\n",
       "  0.0,\n",
       "  23.89,\n",
       "  9.31,\n",
       "  13.45,\n",
       "  0.0,\n",
       "  10.77825,\n",
       "  0.18,\n",
       "  0.74825,\n",
       "  9.0625,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  5.8725,\n",
       "  15.71125,\n",
       "  10.947,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  10.77825,\n",
       "  1.0125,\n",
       "  0.9,\n",
       "  19.46875,\n",
       "  0.6525,\n",
       "  0.47825,\n",
       "  10.8625,\n",
       "  13.91675,\n",
       "  0.75925,\n",
       "  0.0,\n",
       "  9.0625,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  10.44075,\n",
       "  26.427,\n",
       "  5.7655,\n",
       "  1.18125,\n",
       "  14.90125,\n",
       "  0.675,\n",
       "  0.0,\n",
       "  4.725,\n",
       "  9.31,\n",
       "  2.44125,\n",
       "  9.50125,\n",
       "  4.2525,\n",
       "  3.8475,\n",
       "  20.53125,\n",
       "  0.18,\n",
       "  10.44075,\n",
       "  4.55625,\n",
       "  1.49625,\n",
       "  0.0,\n",
       "  11.8375,\n",
       "  0.50625,\n",
       "  10.77825,\n",
       "  3.87575,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.928,\n",
       "  9.625,\n",
       "  0.95625,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.62825,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.35,\n",
       "  10.17625,\n",
       "  1.4175,\n",
       "  0.0,\n",
       "  12.65125,\n",
       "  15.52,\n",
       "  0.0,\n",
       "  3.122,\n",
       "  18.7425,\n",
       "  0.0,\n",
       "  1.60875,\n",
       "  0.0,\n",
       "  9.72075,\n",
       "  0.75925,\n",
       "  0.0,\n",
       "  10.8625,\n",
       "  0.70875,\n",
       "  17.84875,\n",
       "  0.945,\n",
       "  0.4275,\n",
       "  41.53,\n",
       "  1.31625,\n",
       "  0.253,\n",
       "  2.75625,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.72,\n",
       "  6.84,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.74625,\n",
       "  0.91125,\n",
       "  0.0,\n",
       "  3.94875,\n",
       "  10.33375,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  19.80625,\n",
       "  1.24325,\n",
       "  11.74,\n",
       "  2.8145,\n",
       "  0.0,\n",
       "  4.78125,\n",
       "  0.0,\n",
       "  16.76875,\n",
       "  0.0,\n",
       "  0.91125,\n",
       "  0.945,\n",
       "  10.525,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.1375,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  33.6495,\n",
       "  0.0,\n",
       "  17.702,\n",
       "  0.0,\n",
       "  1.18125,\n",
       "  8.9725,\n",
       "  0.0,\n",
       "  10.6095,\n",
       "  0.0,\n",
       "  3.2175,\n",
       "  123.5875,\n",
       "  0.0,\n",
       "  2.44675,\n",
       "  0.64125,\n",
       "  2.48625,\n",
       "  3.15,\n",
       "  4.21875,\n",
       "  10.17625,\n",
       "  6.075,\n",
       "  11.56,\n",
       "  0.0,\n",
       "  22.97875,\n",
       "  10.975,\n",
       "  4.8825,\n",
       "  10.15375,\n",
       "  2.27825,\n",
       "  10.01875,\n",
       "  0.0,\n",
       "  1.097,\n",
       "  0.6525,\n",
       "  1.4175,\n",
       "  11.79075,\n",
       "  0.422,\n",
       "  1.3895,\n",
       "  18.52375,\n",
       "  9.85,\n",
       "  0.0,\n",
       "  11.79075,\n",
       "  0.0,\n",
       "  0.928,\n",
       "  0.765,\n",
       "  0.422,\n",
       "  10.8625,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  10.62,\n",
       "  1.06875,\n",
       "  1.62,\n",
       "  7.29,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.50625,\n",
       "  0.0,\n",
       "  2.205,\n",
       "  1.11375,\n",
       "  0.0,\n",
       "  1.4345,\n",
       "  0.0,\n",
       "  1.4175,\n",
       "  4.82625,\n",
       "  0.2025,\n",
       "  2.28375,\n",
       "  1.7325,\n",
       "  1.0125,\n",
       "  0.96175,\n",
       "  1.94075,\n",
       "  0.0,\n",
       "  0.512,\n",
       "  2.27825,\n",
       "  11.02,\n",
       "  0.0,\n",
       "  7.36325,\n",
       "  3.07125,\n",
       "  47.0425,\n",
       "  0.7875,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  12.04375,\n",
       "  0.0,\n",
       "  1.49625,\n",
       "  2.717,\n",
       "  1.4625,\n",
       "  0.0,\n",
       "  10.452,\n",
       "  22.77625,\n",
       "  0.0,\n",
       "  1.33875,\n",
       "  0.86625,\n",
       "  0.0,\n",
       "  0.63,\n",
       "  10.77825,\n",
       "  16.58,\n",
       "  0.0,\n",
       "  14.94,\n",
       "  10.01875,\n",
       "  0.50625,\n",
       "  0.0,\n",
       "  37.1875,\n",
       "  9.50125,\n",
       "  0.80425,\n",
       "  0.0,\n",
       "  11.0875,\n",
       "  7.09325,\n",
       "  0.0,\n",
       "  1.0125,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  9.2425,\n",
       "  11.12125,\n",
       "  0.0,\n",
       "  11.2,\n",
       "  0.0,\n",
       "  0.91125,\n",
       "  0.0,\n",
       "  4.1345,\n",
       "  1.603,\n",
       "  1.817,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.5355,\n",
       "  1.4345,\n",
       "  15.897,\n",
       "  0.0,\n",
       "  3.07125,\n",
       "  0.0,\n",
       "  0.4725,\n",
       "  0.59075,\n",
       "  0.19125,\n",
       "  0.0,\n",
       "  4.6405,\n",
       "  0.0,\n",
       "  2.775,\n",
       "  2.86875,\n",
       "  0.0,\n",
       "  2.86875,\n",
       "  10.6095,\n",
       "  14.62,\n",
       "  0.0,\n",
       "  9.6475,\n",
       "  0.0,\n",
       "  0.0845,\n",
       "  0.16875,\n",
       "  0.0,\n",
       "  11.28425,\n",
       "  3.122,\n",
       "  0.0,\n",
       "  1.5355,\n",
       "  11.88625,\n",
       "  10.77825,\n",
       "  11.62175,\n",
       "  4.33125,\n",
       "  3.375,\n",
       "  12.055,\n",
       "  0.0,\n",
       "  2.19375,\n",
       "  0.0,\n",
       "  12.372,\n",
       "  0.54,\n",
       "  0.0,\n",
       "  5.805,\n",
       "  9.22125,\n",
       "  1.3895,\n",
       "  1.097,\n",
       "  0.0,\n",
       "  2.34,\n",
       "  0.4725,\n",
       "  2.24425,\n",
       "  3.16875,\n",
       "  0.0,\n",
       "  2.835,\n",
       "  0.315,\n",
       "  0.0,\n",
       "  10.75,\n",
       "  8.24,\n",
       "  0.0,\n",
       "  1.35,\n",
       "  0.0,\n",
       "  0.54,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.18125,\n",
       "  0.84375,\n",
       "  0.0,\n",
       "  14.2375,\n",
       "  10.8625,\n",
       "  0.928,\n",
       "  3.20625,\n",
       "  1.31625,\n",
       "  0.0,\n",
       "  6.15,\n",
       "  2.1095,\n",
       "  0.72,\n",
       "  0.0,\n",
       "  1.18125,\n",
       "  13.80625,\n",
       "  6.075,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5345,\n",
       "  1.0125,\n",
       "  10.12,\n",
       "  2.86875,\n",
       "  19.21,\n",
       "  0.95625,\n",
       "  1.98,\n",
       "  0.0,\n",
       "  0.945,\n",
       "  18.36,\n",
       "  1.81125,\n",
       "  0.675,\n",
       "  1.4175,\n",
       "  0.675,\n",
       "  2.025,\n",
       "  1.72125,\n",
       "  0.4725,\n",
       "  18.372,\n",
       "  0.0,\n",
       "  1.142,\n",
       "  0.0,\n",
       "  1.052,\n",
       "  0.3375,\n",
       "  5.92325,\n",
       "  0.0,\n",
       "  4.922,\n",
       "  0.0,\n",
       "  18.9625,\n",
       "  0.0,\n",
       "  18.163,\n",
       "  7.98125,\n",
       "  0.0,\n",
       "  1.90625,\n",
       "  0.07875,\n",
       "  4.725,\n",
       "  0.253,\n",
       "  0.0,\n",
       "  11.025,\n",
       "  1.052,\n",
       "  0.0,\n",
       "  0.96175,\n",
       "  0.0,\n",
       "  14.40625,\n",
       "  1.49625,\n",
       "  11.90325,\n",
       "  9.5125,\n",
       "  10.66,\n",
       "  10.6095,\n",
       "  0.0,\n",
       "  0.59075,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.45825,\n",
       "  0.4895,\n",
       "  6.66575,\n",
       "  17.89375,\n",
       "  10.4125,\n",
       "  1.4345,\n",
       "  3.7125,\n",
       "  2.205,\n",
       "  13.12,\n",
       "  0.0,\n",
       "  1.2655,\n",
       "  7.29,\n",
       "  6.075,\n",
       "  21.19,\n",
       "  10.17625,\n",
       "  1.18125,\n",
       "  2.295,\n",
       "  0.0,\n",
       "  11.62175,\n",
       "  10.6095,\n",
       "  1.8225,\n",
       "  1.60875,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  9.04,\n",
       "  0.6075,\n",
       "  0.0,\n",
       "  1.17,\n",
       "  1.35,\n",
       "  10.8625,\n",
       "  0.75925,\n",
       "  6.21,\n",
       "  10.7275,\n",
       "  1.2375,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.422,\n",
       "  0.39375,\n",
       "  17.78125,\n",
       "  0.81,\n",
       "  10.0975,\n",
       "  0.405,\n",
       "  0.0,\n",
       "  2.3625,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.45,\n",
       "  7.32375,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.55125,\n",
       "  11.11575,\n",
       "  10.6095,\n",
       "  1.215,\n",
       "  2.6325,\n",
       "  0.0,\n",
       "  3.14425,\n",
       "  0.0,\n",
       "  10.57,\n",
       "  0.0,\n",
       "  0.63,\n",
       "  3.38625,\n",
       "  7.47,\n",
       "  26.21875,\n",
       "  4.86,\n",
       "  10.7275,\n",
       "  1.6875,\n",
       "  1.18125,\n",
       "  ...],\n",
       " 'production_model_prediction': [0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  2.0738914,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.7470818,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.7812064,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  2.0738914,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  2.0738914,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.7812064,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.9658754,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  2.0196548,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.7269697,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.0196548,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.9658754,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.7470818,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.9658754,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.0196548,\n",
       "  0.0,\n",
       "  1.9658754,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.9658754,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.9658754,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  2.0738914,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.7812064,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.9658754,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.7269697,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.7269697,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  2.0196548,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.7812064,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.9658754,\n",
       "  2.0738914,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.6731903,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.9658754,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  2.0738914,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.9658754,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.9658754,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.0738914,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.9658754,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.7812064,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.9658754,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  2.0196548,\n",
       "  0.0,\n",
       "  1.9658754,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.7812064,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.0738914,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.7812064,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.40016,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.6731903,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.7812064,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.0738914,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.9658754,\n",
       "  0.6731903,\n",
       "  0.0,\n",
       "  0.6731903,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.9658754,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.0738914,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  1.292685,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  ...]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fd8039d-0c2c-4b09-b51a-47b3947113aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_g = pd.DataFrame.from_dict(pred_df).groupby(['userId'])\n",
    "pd_data = pd.DataFrame.from_dict(pred_df)\n",
    "\n",
    "pd_data = pd_data.sort_values('userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01a22ae5-a287-4a7d-bbd1-69c4ad901a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prod label NDCG  0.9985227356763211\n",
      "pred NDCG  0.8548740351597712\n",
      "combined score pred  0.9993704355962312\n"
     ]
    }
   ],
   "source": [
    "print(\"prod label NDCG \",calc_NDCG(pd_data, \"production_model_prediction_unified\"))\n",
    "print(\"pred NDCG \",calc_NDCG(pd_data, \"prediction\"))\n",
    "print(\"combined score pred \",calc_NDCG(pd_data, \"production_model_prediction\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e853585-61e4-4c05-848f-cc3839656d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>postId</th>\n",
       "      <th>groundtruth</th>\n",
       "      <th>groundtruth2</th>\n",
       "      <th>groundtruth3</th>\n",
       "      <th>groundtruth4</th>\n",
       "      <th>prediction</th>\n",
       "      <th>production_model_prediction_unified</th>\n",
       "      <th>production_model_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2173758363</td>\n",
       "      <td>5752863345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.181378</td>\n",
       "      <td>0.60750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2723484960</td>\n",
       "      <td>5488191835</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.864940</td>\n",
       "      <td>10.60950</td>\n",
       "      <td>1.292685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>342304182</td>\n",
       "      <td>1511838835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.398786</td>\n",
       "      <td>0.47825</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2629707858</td>\n",
       "      <td>7741613935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.724812</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1184167872</td>\n",
       "      <td>7334551045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.832932</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>2713987278</td>\n",
       "      <td>9128692345</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.557515</td>\n",
       "      <td>9.86125</td>\n",
       "      <td>1.292685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>683883594</td>\n",
       "      <td>7175664145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.155907</td>\n",
       "      <td>1.82825</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>983642004</td>\n",
       "      <td>3348876835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.574244</td>\n",
       "      <td>0.84375</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>67325742</td>\n",
       "      <td>1242147245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.688567</td>\n",
       "      <td>5.87250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>2325601035</td>\n",
       "      <td>7068771935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.864308</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148669 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            userId      postId  groundtruth  groundtruth2  groundtruth3  \\\n",
       "0       2173758363  5752863345          0.0           0.0           0.0   \n",
       "1       2723484960  5488191835          1.0           0.0           0.0   \n",
       "2        342304182  1511838835          0.0           0.0           0.0   \n",
       "3       2629707858  7741613935          0.0           0.0           0.0   \n",
       "4       1184167872  7334551045          0.0           0.0           0.0   \n",
       "...            ...         ...          ...           ...           ...   \n",
       "149995  2713987278  9128692345          1.0           0.0           0.0   \n",
       "149996   683883594  7175664145          0.0           0.0           0.0   \n",
       "149997   983642004  3348876835          0.0           0.0           0.0   \n",
       "149998    67325742  1242147245          0.0           0.0           0.0   \n",
       "149999  2325601035  7068771935          0.0           0.0           0.0   \n",
       "\n",
       "        groundtruth4  prediction  production_model_prediction_unified  \\\n",
       "0                0.0    1.181378                              0.60750   \n",
       "1                0.0    0.864940                             10.60950   \n",
       "2                0.0    4.398786                              0.47825   \n",
       "3                0.0    1.724812                              0.00000   \n",
       "4                0.0    5.832932                              0.00000   \n",
       "...              ...         ...                                  ...   \n",
       "149995           0.0    5.557515                              9.86125   \n",
       "149996           0.0    3.155907                              1.82825   \n",
       "149997           0.0    6.574244                              0.84375   \n",
       "149998           0.0    6.688567                              5.87250   \n",
       "149999           0.0    5.864308                              0.00000   \n",
       "\n",
       "        production_model_prediction  \n",
       "0                          0.000000  \n",
       "1                          1.292685  \n",
       "2                          0.000000  \n",
       "3                          0.000000  \n",
       "4                          0.000000  \n",
       "...                             ...  \n",
       "149995                     1.292685  \n",
       "149996                     0.000000  \n",
       "149997                     0.000000  \n",
       "149998                     0.000000  \n",
       "149999                     0.000000  \n",
       "\n",
       "[148669 rows x 9 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_g.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a547b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_NDCG(pd_data, \"production_model_prediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2c58d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "pd_data['prediction_2'] = 1 / (1 + np.exp(-pd_data.prediction))\n",
    "pd_data['production_model_prediction_2'] = 1 / (1 + np.exp(-pd_data.production_model_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88e9c15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg pred_2  0.8547650448696917\n",
      "prod score  0.9993704355962312\n"
     ]
    }
   ],
   "source": [
    "print(\"ndcg pred_2 \",calc_NDCG(pd_data, \"prediction_2\"))\n",
    "print(\"prod score \",calc_NDCG(pd_data, \"production_model_prediction_2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248577af",
   "metadata": {},
   "source": [
    "## Vplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2770457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 4.926799774169922\n",
      "gmeanOpt: 0.6618\n",
      "fprOpt: 0.36\n",
      "tprOpt: 0.6845\n",
      "Recall:  0.6844631713691397\n",
      "Precision:  0.3878679804146769\n",
      "ROC-AUC:  0.7188664363474768\n",
      "PR-AUC:  0.4159462137856786\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "key = \"unified\"\n",
    "summary = {}\n",
    "summary[key] = {}\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(pred_df['groundtruth'], pred_df['prediction'])\n",
    "gmean = np.sqrt(tpr * (1 - fpr))\n",
    "# Find the optimal threshold\n",
    "index = np.argmax(gmean)\n",
    "thresholdOpt = round(thresholds[index], ndigits = 4)\n",
    "gmeanOpt = round(gmean[index], ndigits = 4)\n",
    "fprOpt = round(fpr[index], ndigits = 4)\n",
    "tprOpt = round(tpr[index], ndigits = 4)\n",
    "\n",
    "print(f'Best Threshold: {thresholdOpt}')\n",
    "summary[key][\"threshold\"] = thresholdOpt\n",
    "print(f'gmeanOpt: {gmeanOpt}')\n",
    "summary[key][\"gmean\"] = gmeanOpt\n",
    "print(f'fprOpt: {fprOpt}')\n",
    "summary[key][\"fprOpt\"] = fprOpt\n",
    "print(f'tprOpt: {tprOpt}')\n",
    "summary[key][\"tprOpt\"] = tprOpt\n",
    "\n",
    "pred = pred_df['prediction'].copy()\n",
    "pred = np.array(pred).astype(float)\n",
    "pred[pred > thresholdOpt] = 1\n",
    "pred[pred != 1] = 0\n",
    "\n",
    "recall = metrics.recall_score(pred_df['groundtruth'], pred)\n",
    "print(\"Recall: \", recall)\n",
    "summary[key][\"recall\"] = recall\n",
    "precision = metrics.precision_score(pred_df['groundtruth'], pred)\n",
    "print(\"Precision: \", precision)\n",
    "summary[key][\"precision\"] = precision\n",
    "\n",
    "roc_auc = metrics.roc_auc_score(pred_df['groundtruth'], pred_df['prediction'])\n",
    "print(\"ROC-AUC: \", roc_auc)\n",
    "summary[key][\"roc_auc\"] = roc_auc\n",
    "pr_auc = metrics.average_precision_score(pred_df['groundtruth'], pred_df['prediction'])\n",
    "print(\"PR-AUC: \", pr_auc)\n",
    "summary[key][\"pr_auc\"] = pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d648a83",
   "metadata": {},
   "source": [
    "## Likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfa67a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 4.729300022125244\n",
      "gmeanOpt: 0.5311\n",
      "fprOpt: 0.4657\n",
      "tprOpt: 0.528\n",
      "Recall:  0.5277516462841016\n",
      "Precision:  0.032003651040403897\n",
      "ROC-AUC:  0.5560587502337504\n",
      "PR-AUC:  0.034294610069489424\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "key = \"unified\"\n",
    "summary = {}\n",
    "summary[key] = {}\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(pred_df['groundtruth2'], pred_df['prediction'])\n",
    "gmean = np.sqrt(tpr * (1 - fpr))\n",
    "# Find the optimal threshold\n",
    "index = np.argmax(gmean)\n",
    "thresholdOpt = round(thresholds[index], ndigits = 4)\n",
    "gmeanOpt = round(gmean[index], ndigits = 4)\n",
    "fprOpt = round(fpr[index], ndigits = 4)\n",
    "tprOpt = round(tpr[index], ndigits = 4)\n",
    "\n",
    "print(f'Best Threshold: {thresholdOpt}')\n",
    "summary[key][\"threshold\"] = thresholdOpt\n",
    "print(f'gmeanOpt: {gmeanOpt}')\n",
    "summary[key][\"gmean\"] = gmeanOpt\n",
    "print(f'fprOpt: {fprOpt}')\n",
    "summary[key][\"fprOpt\"] = fprOpt\n",
    "print(f'tprOpt: {tprOpt}')\n",
    "summary[key][\"tprOpt\"] = tprOpt\n",
    "\n",
    "pred = pred_df['prediction'].copy()\n",
    "pred = np.array(pred).astype(float)\n",
    "pred[pred > thresholdOpt] = 1\n",
    "pred[pred != 1] = 0\n",
    "\n",
    "recall = metrics.recall_score(pred_df['groundtruth2'], pred)\n",
    "print(\"Recall: \", recall)\n",
    "summary[key][\"recall\"] = recall\n",
    "precision = metrics.precision_score(pred_df['groundtruth2'], pred)\n",
    "print(\"Precision: \", precision)\n",
    "summary[key][\"precision\"] = precision\n",
    "\n",
    "roc_auc = metrics.roc_auc_score(pred_df['groundtruth2'], pred_df['prediction'])\n",
    "print(\"ROC-AUC: \", roc_auc)\n",
    "summary[key][\"roc_auc\"] = roc_auc\n",
    "pr_auc = metrics.average_precision_score(pred_df['groundtruth2'], pred_df['prediction'])\n",
    "print(\"PR-AUC: \", pr_auc)\n",
    "summary[key][\"pr_auc\"] = pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf2782",
   "metadata": {},
   "source": [
    "## Shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb942ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 4.517899990081787\n",
      "gmeanOpt: 0.5252\n",
      "fprOpt: 0.496\n",
      "tprOpt: 0.5474\n",
      "Recall:  0.5474006116207951\n",
      "Precision:  0.009614609910030885\n",
      "ROC-AUC:  0.5427348600078105\n",
      "PR-AUC:  0.009525643562408362\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "key = \"unified\"\n",
    "summary = {}\n",
    "summary[key] = {}\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(pred_df['groundtruth3'], pred_df['prediction'])\n",
    "gmean = np.sqrt(tpr * (1 - fpr))\n",
    "# Find the optimal threshold\n",
    "index = np.argmax(gmean)\n",
    "thresholdOpt = round(thresholds[index], ndigits = 4)\n",
    "gmeanOpt = round(gmean[index], ndigits = 4)\n",
    "fprOpt = round(fpr[index], ndigits = 4)\n",
    "tprOpt = round(tpr[index], ndigits = 4)\n",
    "\n",
    "print(f'Best Threshold: {thresholdOpt}')\n",
    "summary[key][\"threshold\"] = thresholdOpt\n",
    "print(f'gmeanOpt: {gmeanOpt}')\n",
    "summary[key][\"gmean\"] = gmeanOpt\n",
    "print(f'fprOpt: {fprOpt}')\n",
    "summary[key][\"fprOpt\"] = fprOpt\n",
    "print(f'tprOpt: {tprOpt}')\n",
    "summary[key][\"tprOpt\"] = tprOpt\n",
    "\n",
    "pred = pred_df['prediction'].copy()\n",
    "pred = np.array(pred).astype(float)\n",
    "pred[pred > thresholdOpt] = 1\n",
    "pred[pred != 1] = 0\n",
    "\n",
    "recall = metrics.recall_score(pred_df['groundtruth3'], pred)\n",
    "print(\"Recall: \", recall)\n",
    "summary[key][\"recall\"] = recall\n",
    "precision = metrics.precision_score(pred_df['groundtruth3'], pred)\n",
    "print(\"Precision: \", precision)\n",
    "summary[key][\"precision\"] = precision\n",
    "\n",
    "roc_auc = metrics.roc_auc_score(pred_df['groundtruth3'], pred_df['prediction'])\n",
    "print(\"ROC-AUC: \", roc_auc)\n",
    "summary[key][\"roc_auc\"] = roc_auc\n",
    "pr_auc = metrics.average_precision_score(pred_df['groundtruth3'], pred_df['prediction'])\n",
    "print(\"PR-AUC: \", pr_auc)\n",
    "summary[key][\"pr_auc\"] = pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befe02af",
   "metadata": {},
   "source": [
    "## Favs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0cd0ad5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 4.035600185394287\n",
      "gmeanOpt: 0.5106\n",
      "fprOpt: 0.5641\n",
      "tprOpt: 0.5982\n",
      "Recall:  0.5982381206620395\n",
      "Precision:  0.026441541892322395\n",
      "ROC-AUC:  0.5266633281342903\n",
      "PR-AUC:  0.025878794475187046\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "key = \"unified\"\n",
    "summary = {}\n",
    "summary[key] = {}\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(pred_df['groundtruth4'], pred_df['prediction'])\n",
    "gmean = np.sqrt(tpr * (1 - fpr))\n",
    "# Find the optimal threshold\n",
    "index = np.argmax(gmean)\n",
    "thresholdOpt = round(thresholds[index], ndigits = 4)\n",
    "gmeanOpt = round(gmean[index], ndigits = 4)\n",
    "fprOpt = round(fpr[index], ndigits = 4)\n",
    "tprOpt = round(tpr[index], ndigits = 4)\n",
    "\n",
    "print(f'Best Threshold: {thresholdOpt}')\n",
    "summary[key][\"threshold\"] = thresholdOpt\n",
    "print(f'gmeanOpt: {gmeanOpt}')\n",
    "summary[key][\"gmean\"] = gmeanOpt\n",
    "print(f'fprOpt: {fprOpt}')\n",
    "summary[key][\"fprOpt\"] = fprOpt\n",
    "print(f'tprOpt: {tprOpt}')\n",
    "summary[key][\"tprOpt\"] = tprOpt\n",
    "\n",
    "pred = pred_df['prediction'].copy()\n",
    "pred = np.array(pred).astype(float)\n",
    "pred[pred > thresholdOpt] = 1\n",
    "pred[pred != 1] = 0\n",
    "\n",
    "recall = metrics.recall_score(pred_df['groundtruth4'], pred)\n",
    "print(\"Recall: \", recall)\n",
    "summary[key][\"recall\"] = recall\n",
    "precision = metrics.precision_score(pred_df['groundtruth4'], pred)\n",
    "print(\"Precision: \", precision)\n",
    "summary[key][\"precision\"] = precision\n",
    "\n",
    "roc_auc = metrics.roc_auc_score(pred_df['groundtruth4'], pred_df['prediction'])\n",
    "print(\"ROC-AUC: \", roc_auc)\n",
    "summary[key][\"roc_auc\"] = roc_auc\n",
    "pr_auc = metrics.average_precision_score(pred_df['groundtruth4'], pred_df['prediction'])\n",
    "print(\"PR-AUC: \", pr_auc)\n",
    "summary[key][\"pr_auc\"] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6cbc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"unified\"\n",
    "summary = {}\n",
    "summary[key] = {}\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(pred_df['groundtruth'], pred_df['production_model_prediction_unified'])\n",
    "gmean = np.sqrt(tpr * (1 - fpr))\n",
    "# Find the optimal threshold\n",
    "index = np.argmax(gmean)\n",
    "thresholdOpt = round(thresholds[index], ndigits = 4)\n",
    "gmeanOpt = round(gmean[index], ndigits = 4)\n",
    "fprOpt = round(fpr[index], ndigits = 4)\n",
    "tprOpt = round(tpr[index], ndigits = 4)\n",
    "\n",
    "print(f'Best Threshold: {thresholdOpt}')\n",
    "summary[key][\"threshold\"] = thresholdOpt\n",
    "print(f'gmeanOpt: {gmeanOpt}')\n",
    "summary[key][\"gmean\"] = gmeanOpt\n",
    "print(f'fprOpt: {fprOpt}')\n",
    "summary[key][\"fprOpt\"] = fprOpt\n",
    "print(f'tprOpt: {tprOpt}')\n",
    "summary[key][\"tprOpt\"] = tprOpt\n",
    "\n",
    "pred = pred_df['production_model_prediction_unified'].copy()\n",
    "pred = np.array(pred).astype(float)\n",
    "pred[pred > thresholdOpt] = 1\n",
    "pred[pred != 1] = 0\n",
    "\n",
    "recall = metrics.recall_score(pred_df['groundtruth'], pred)\n",
    "print(\"Recall: \", recall)\n",
    "summary[key][\"recall\"] = recall\n",
    "precision = metrics.precision_score(pred_df['groundtruth'], pred)\n",
    "print(\"Precision: \", precision)\n",
    "summary[key][\"precision\"] = precision\n",
    "\n",
    "roc_auc = metrics.roc_auc_score(pred_df['groundtruth'], pred_df['production_model_prediction_unified'])\n",
    "print(\"ROC-AUC: \", roc_auc)\n",
    "summary[key][\"roc_auc\"] = roc_auc\n",
    "pr_auc = metrics.average_precision_score(pred_df['groundtruth'], pred_df['production_model_prediction_unified'])\n",
    "print(\"PR-AUC: \", pr_auc)\n",
    "summary[key][\"pr_auc\"] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f7d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support,roc_curve,auc\n",
    "fpr, tpr, thresholds = roc_curve(pd_data['groundtruth'], pd_data['production_model_prediction_combined'], pos_label=1)\n",
    "print(\" auc is \",auc(fpr, tpr))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m100"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
